# 14.5 温度采样与Top-k采样策略

> **设计思想**：掌握文本生成的采样策略和优化技术，理解如何控制生成文本的多样性和质量

## 本节概述

文本生成的质量和多样性很大程度上取决于采样策略的选择。不同的采样策略可以在创造性、一致性和准确性之间找到不同的平衡点。本节将深入探讨温度采样、Top-k采样、Top-p采样等核心采样策略的原理、实现和应用场景，帮助读者掌握如何通过采样策略控制文本生成的效果。

## 学习目标

完成本节学习后，你将：

- ✅ **掌握温度采样的原理**：理解温度参数对生成多样性的控制机制
- ✅ **学会Top-k采样的实现**：掌握截断策略在质量控制中的应用
- ✅ **理解Top-p采样的优势**：掌握动态选择策略的实现原理
- ✅ **掌握采样策略的组合使用**：理解如何结合多种策略优化生成效果
- ✅ **具备采样策略实现能力**：能够编写高效的文本生成采样算法

## 贪心解码vs随机采样

### 贪心解码

贪心解码是最简单的生成策略，它总是选择概率最高的token：

```java
public class GreedyDecoder {
    public int decode(Variable logits) {
        // 选择概率最高的token
        return logits.argmax(-1).getData().toInt();
    }
    
    public List<Integer> decodeSequence(Variable logitsSequence) {
        List<Integer> tokens = new ArrayList<>();
        for (int i = 0; i < logitsSequence.getShape().get(0); i++) {
            Variable logits = logitsSequence.slice(i, i + 1);
            tokens.add(decode(logits));
        }
        return tokens;
    }
}
```

**优点**：
- 确定性输出，相同输入总是产生相同结果
- 计算效率高
- 生成结果通常语法正确

**缺点**：
- 缺乏创造性，容易产生重复和乏味的文本
- 无法探索概率分布中的其他可能性

### 随机采样

随机采样从完整的概率分布中采样token：

```java
public class RandomSampler {
    public int sample(Variable logits) {
        // 计算概率分布
        Variable probs = logits.softmax(-1);
        // 从分布中采样
        return sampleFromDistribution(probs);
    }
    
    private int sampleFromDistribution(Variable probs) {
        // 实现从概率分布中采样的算法
        double rand = Math.random();
        double cumulative = 0.0;
        
        float[] probArray = probs.getData().toFloatArray();
        for (int i = 0; i < probArray.length; i++) {
            cumulative += probArray[i];
            if (rand < cumulative) {
                return i;
            }
        }
        
        return probArray.length - 1;  // fallback
    }
}
```

**优点**：
- 生成结果具有多样性
- 能够探索不同的可能性

**缺点**：
- 可能采样到低概率、低质量的token
- 生成结果可能语法不正确或语义不连贯

## 温度采样

### 数学原理

温度采样通过引入温度参数T来调整概率分布：

```
P(x_i) = exp(logit_i / T) / Σ_j exp(logit_j / T)
```

其中T是温度参数：
- T = 1：原始分布
- T → 0：趋向贪心解码
- T → ∞：趋向均匀分布

### 实现代码

```java
public class TemperatureSampler {
    private double temperature;
    
    public TemperatureSampler(double temperature) {
        this.temperature = temperature;
    }
    
    public int sample(Variable logits) {
        // 应用温度参数
        Variable adjustedLogits = logits.div(temperature);
        
        // 计算调整后的概率分布
        Variable probs = adjustedLogits.softmax(-1);
        
        // 采样
        return sampleFromDistribution(probs);
    }
    
    public Variable adjustLogits(Variable logits) {
        return logits.div(temperature);
    }
}
```

### 温度参数的影响

```java
public class TemperatureAnalysis {
    public void analyzeTemperatureEffects(Variable logits) {
        double[] temperatures = {0.1, 0.5, 1.0, 1.5, 2.0};
        
        for (double temp : temperatures) {
            TemperatureSampler sampler = new TemperatureSampler(temp);
            Variable adjustedLogits = sampler.adjustLogits(logits);
            Variable probs = adjustedLogits.softmax(-1);
            
            // 分析概率分布的熵
            double entropy = calculateEntropy(probs);
            
            // 分析top-k概率和
            double topKSum = calculateTopKProbabilitySum(probs, 5);
            
            System.out.printf("Temperature: %.1f, Entropy: %.4f, Top-5 Sum: %.4f%n", 
                            temp, entropy, topKSum);
        }
    }
    
    private double calculateEntropy(Variable probs) {
        Variable logProbs = probs.log();
        Variable entropy = probs.mul(logProbs).sum(-1).neg();
        return entropy.getData().getFloat();
    }
    
    private double calculateTopKProbabilitySum(Variable probs, int k) {
        Variable sortedProbs = probs.sort(-1, true);
        Variable topKProbs = sortedProbs.slice(0, k);
        return topKProbs.sum(-1).getData().getFloat();
    }
}
```

### 温度采样的应用场景

| 应用场景 | 推荐温度值 | 原因 |
|----------|------------|------|
| 事实问答 | 0.1-0.3 | 需要准确、确定的答案 |
| 创意写作 | 0.7-1.0 | 需要创造性和多样性 |
| 代码生成 | 0.2-0.5 | 需要语法正确性 |
| 对话生成 | 0.8-1.2 | 需要自然、多样化的回复 |

## Top-k采样

### 设计思想

Top-k采样通过只考虑概率最高的k个token来避免采样到低质量的token：

1. 计算完整的概率分布
2. 选择概率最高的k个token
3. 将其他token的概率设为0
4. 重新归一化概率分布
5. 从截断的分布中采样

### 实现代码

```java
public class TopKSampler {
    private int k;
    
    public TopKSampler(int k) {
        this.k = k;
    }
    
    public int sample(Variable logits) {
        // 获取top-k的logits
        Variable topKLogits = getTopKLogits(logits, k);
        
        // 计算概率分布
        Variable probs = topKLogits.softmax(-1);
        
        // 采样
        return sampleFromDistribution(probs);
    }
    
    private Variable getTopKLogits(Variable logits, int k) {
        int vocabSize = logits.getShape().get(-1);
        
        // 获取top-k索引
        Variable topKIndices = logits.argsort(-1, true).slice(0, k);
        
        // 创建掩码
        Variable mask = createTopKMask(vocabSize, topKIndices);
        
        // 应用掩码
        Variable maskedLogits = logits.where(mask, Float.NEGATIVE_INFINITY);
        
        return maskedLogits;
    }
    
    private Variable createTopKMask(int vocabSize, Variable topKIndices) {
        int[] indices = topKIndices.getData().toIntArray();
        boolean[] maskArray = new boolean[vocabSize];
        
        for (int index : indices) {
            maskArray[index] = true;
        }
        
        // 转换为NdArray
        float[] maskValues = new float[vocabSize];
        for (int i = 0; i < vocabSize; i++) {
            maskValues[i] = maskArray[i] ? 0.0f : Float.NEGATIVE_INFINITY;
        }
        
        return new Variable(NdArray.of(maskValues));
    }
}
```

### Top-k采样的优化

```java
public class OptimizedTopKSampler {
    private int k;
    
    public OptimizedTopKSampler(int k) {
        this.k = k;
    }
    
    public int sample(Variable logits) {
        // 使用快速选择算法找到top-k
        int[] topKIndices = quickSelectTopK(logits.getData().toFloatArray(), k);
        
        // 只计算top-k的softmax
        float[] topKLogits = extractTopKValues(logits.getData().toFloatArray(), topKIndices);
        float[] topKProbs = softmax(topKLogits);
        
        // 从top-k中采样
        int selectedIndex = sampleFromDistribution(topKProbs);
        return topKIndices[selectedIndex];
    }
    
    private int[] quickSelectTopK(float[] logits, int k) {
        // 实现快速选择算法找到top-k索引
        // 这比完全排序更高效
        Integer[] indices = new Integer[logits.length];
        for (int i = 0; i < logits.length; i++) {
            indices[i] = i;
        }
        
        // 使用部分排序找到top-k
        Arrays.sort(indices, (a, b) -> Float.compare(logits[b], logits[a]));
        
        int[] result = new int[k];
        for (int i = 0; i < k; i++) {
            result[i] = indices[i];
        }
        
        return result;
    }
    
    private float[] extractTopKValues(float[] logits, int[] indices) {
        float[] values = new float[indices.length];
        for (int i = 0; i < indices.length; i++) {
            values[i] = logits[indices[i]];
        }
        return values;
    }
    
    private float[] softmax(float[] logits) {
        float maxLogit = Arrays.stream(logits).max().orElse(0.0f);
        float[] expLogits = new float[logits.length];
        float sum = 0.0f;
        
        for (int i = 0; i < logits.length; i++) {
            expLogits[i] = (float) Math.exp(logits[i] - maxLogit);
            sum += expLogits[i];
        }
        
        for (int i = 0; i < expLogits.length; i++) {
            expLogits[i] /= sum;
        }
        
        return expLogits;
    }
}
```

## Top-p采样（核采样）

### 设计思想

Top-p采样（也称为核采样）动态选择累积概率超过阈值p的最小token集合：

1. 计算概率分布
2. 按概率降序排列
3. 计算累积概率
4. 选择累积概率首次超过p的最小集合
5. 从该集合中采样

### 实现代码

```java
public class TopPSampler {
    private double p;
    
    public TopPSampler(double p) {
        this.p = p;
    }
    
    public int sample(Variable logits) {
        // 计算概率分布
        Variable probs = logits.softmax(-1);
        
        // 获取核采样结果
        Variable nucleusProbs = getNucleusProbs(probs, p);
        
        // 采样
        return sampleFromDistribution(nucleusProbs);
    }
    
    private Variable getNucleusProbs(Variable probs, double p) {
        int vocabSize = probs.getShape().get(-1);
        
        // 获取排序索引
        Variable sortedIndices = probs.argsort(-1, true);
        Variable sortedProbs = probs.sort(-1, true);
        
        // 计算累积概率
        Variable cumulativeProbs = sortedProbs.cumsum(-1);
        
        // 找到累积概率超过p的位置
        Variable mask = cumulativeProbs.gt(p);
        
        // 创建核掩码
        Variable nucleusMask = createNucleusMask(vocabSize, sortedIndices, mask);
        
        // 应用掩码并重新归一化
        Variable maskedProbs = probs.where(nucleusMask, 0.0f);
        Variable normalizedProbs = maskedProbs.div(maskedProbs.sum(-1, true));
        
        return normalizedProbs;
    }
    
    private Variable createNucleusMask(int vocabSize, Variable sortedIndices, Variable mask) {
        // 实现核掩码创建逻辑
        boolean[] maskArray = new boolean[vocabSize];
        int[] indices = sortedIndices.getData().toIntArray();
        boolean[] maskValues = mask.getData().toBooleanArray();
        
        for (int i = 0; i < maskValues.length; i++) {
            if (!maskValues[i]) {  // 保留累积概率未超过p的token
                maskArray[indices[i]] = true;
            }
        }
        
        // 至少保留一个token
        if (Arrays.stream(maskArray).noneMatch(b -> b)) {
            maskArray[indices[0]] = true;
        }
        
        // 转换为NdArray
        float[] maskValuesFloat = new float[vocabSize];
        for (int i = 0; i < vocabSize; i++) {
            maskValuesFloat[i] = maskArray[i] ? 0.0f : Float.NEGATIVE_INFINITY;
        }
        
        return new Variable(NdArray.of(maskValuesFloat));
    }
}
```

## 采样策略的组合使用

### 温度+Top-k组合

```java
public class TemperatureTopKSampler {
    private double temperature;
    private int k;
    
    public TemperatureTopKSampler(double temperature, int k) {
        this.temperature = temperature;
        this.k = k;
    }
    
    public int sample(Variable logits) {
        // 1. 应用温度参数
        Variable adjustedLogits = logits.div(temperature);
        
        // 2. Top-k截断
        Variable topKLogits = getTopKLogits(adjustedLogits, k);
        
        // 3. 计算概率分布
        Variable probs = topKLogits.softmax(-1);
        
        // 4. 采样
        return sampleFromDistribution(probs);
    }
}
```

### 温度+Top-p组合

```java
public class TemperatureTopPSampler {
    private double temperature;
    private double p;
    
    public TemperatureTopPSampler(double temperature, double p) {
        this.temperature = temperature;
        this.p = p;
    }
    
    public int sample(Variable logits) {
        // 1. 应用温度参数
        Variable adjustedLogits = logits.div(temperature);
        
        // 2. 计算概率分布
        Variable probs = adjustedLogits.softmax(-1);
        
        // 3. Top-p截断
        Variable nucleusProbs = getNucleusProbs(probs, p);
        
        // 4. 采样
        return sampleFromDistribution(nucleusProbs);
    }
}
```

## 采样策略评估

### 质量评估指标

```java
public class SamplingEvaluator {
    public SamplingMetrics evaluateSamplingStrategy(
            LanguageModel model, 
            List<String> prompts, 
            SamplingStrategy strategy) {
        
        List<String> generatedTexts = new ArrayList<>();
        long totalTime = 0;
        int totalTokens = 0;
        
        for (String prompt : prompts) {
            long startTime = System.currentTimeMillis();
            
            String generated = model.generate(prompt, strategy);
            generatedTexts.add(generated);
            
            long endTime = System.currentTimeMillis();
            totalTime += (endTime - startTime);
            totalTokens += countTokens(generated);
        }
        
        // 计算各种指标
        double avgGenerationTime = (double) totalTime / prompts.size();
        double tokensPerSecond = (double) totalTokens / (totalTime / 1000.0);
        double diversityScore = calculateDiversity(generatedTexts);
        double coherenceScore = calculateCoherence(generatedTexts);
        
        return new SamplingMetrics(
            avgGenerationTime,
            tokensPerSecond,
            diversityScore,
            coherenceScore
        );
    }
    
    private double calculateDiversity(List<String> texts) {
        // 计算生成文本的多样性
        // 可以使用n-gram重复率、词汇丰富度等指标
        Set<String> allNgrams = new HashSet<>();
        int totalNgrams = 0;
        
        for (String text : texts) {
            List<String> ngrams = extractNgrams(text, 3);
            allNgrams.addAll(ngrams);
            totalNgrams += ngrams.size();
        }
        
        return (double) allNgrams.size() / totalNgrams;
    }
    
    private double calculateCoherence(List<String> texts) {
        // 计算生成文本的连贯性
        // 可以使用语言模型评分、语法正确性检查等
        double totalScore = 0.0;
        
        for (String text : texts) {
            double score = languageModel.score(text);
            totalScore += score;
        }
        
        return totalScore / texts.size();
    }
}
```

### 策略比较实验

```java
public class SamplingStrategyComparison {
    public void compareStrategies(LanguageModel model, List<String> testPrompts) {
        // 定义不同的采样策略
        List<SamplingStrategy> strategies = Arrays.asList(
            new GreedyStrategy(),
            new TemperatureStrategy(0.5),
            new TemperatureStrategy(1.0),
            new TopKStrategy(50),
            new TopKStrategy(100),
            new TopPStrategy(0.9),
            new TopPStrategy(0.95),
            new TemperatureTopKStrategy(0.8, 50),
            new TemperatureTopPStrategy(0.9, 0.9)
        );
        
        System.out.println("Sampling Strategy Comparison Results:");
        System.out.println("=====================================");
        
        for (SamplingStrategy strategy : strategies) {
            SamplingMetrics metrics = evaluateStrategy(model, testPrompts, strategy);
            
            System.out.printf("%-30s | Time: %.2fms | Speed: %.1f tok/s | " +
                            "Diversity: %.3f | Coherence: %.3f%n",
                            strategy.getName(),
                            metrics.getAvgGenerationTime(),
                            metrics.getTokensPerSecond(),
                            metrics.getDiversityScore(),
                            metrics.getCoherenceScore());
        }
    }
}
```

## 实际应用案例

### 对话系统中的采样策略

```java
public class DialogueSamplingManager {
    private Map<String, SamplingStrategy> strategyMap;
    
    public DialogueSamplingManager() {
        strategyMap = new HashMap<>();
        strategyMap.put("greeting", new TemperatureTopPStrategy(0.8, 0.9));
        strategyMap.put("question", new TemperatureTopKStrategy(0.7, 50));
        strategyMap.put("creative", new TemperatureTopPStrategy(1.0, 0.95));
        strategyMap.put("factual", new TemperatureStrategy(0.3));
    }
    
    public String generateResponse(DialogueContext context) {
        // 根据对话上下文选择采样策略
        SamplingStrategy strategy = selectStrategy(context);
        
        return languageModel.generate(context.getPrompt(), strategy);
    }
    
    private SamplingStrategy selectStrategy(DialogueContext context) {
        String intent = context.getIntent();
        if (strategyMap.containsKey(intent)) {
            return strategyMap.get(intent);
        }
        
        // 默认策略
        return new TemperatureTopPStrategy(0.9, 0.9);
    }
}
```

### 文本摘要中的采样策略

```java
public class SummarizationSampler {
    public String generateSummary(String document, SummaryConfig config) {
        // 对于摘要任务，通常使用较低的温度以确保准确性
        SamplingStrategy strategy = new TemperatureTopKStrategy(
            config.getTemperature(),  // 通常为0.5-0.7
            config.getTopK()          // 通常为30-50
        );
        
        return languageModel.generate(createSummaryPrompt(document), strategy);
    }
}
```

## 本节小结

本节深入探讨了文本生成的采样策略和优化技术，我们学习了：

1. **贪心解码vs随机采样**：理解了确定性与多样性之间的权衡
2. **温度采样的原理**：掌握了温度参数对生成多样性的控制机制
3. **Top-k采样的实现**：学会了截断策略在质量控制中的应用
4. **Top-p采样的优势**：掌握了动态选择策略的实现原理
5. **采样策略的组合使用**：理解了如何结合多种策略优化生成效果

采样策略是控制文本生成质量的关键技术，不同的策略适用于不同的应用场景。通过合理选择和组合采样策略，我们可以生成既具有创造性又保持高质量的文本内容。

在下一节中，我们将学习大模型优化与微调技术，掌握工业级应用的关键技术。