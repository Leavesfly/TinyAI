# 9.4 æ–‡æœ¬åˆ†ç±»å®æˆ˜ï¼šæƒ…æ„Ÿåˆ†ææŒ‘æˆ˜

> **æœ¬èŠ‚å­¦ä¹ ç›®æ ‡**ï¼šæ•´åˆæ‰€å­¦çŸ¥è¯†ï¼Œæ„å»ºä¸€ä¸ªå®Œæ•´çš„æƒ…æ„Ÿåˆ†æç³»ç»Ÿ

## å†…å®¹æ¦‚è§ˆ

å‰é¢å‡ èŠ‚å­¦äº†å¾ˆå¤š"å·¥å…·"ï¼š
- 9.1ï¼šæ–‡æœ¬é¢„å¤„ç† â†’ æŠŠåŸææ–™"æ´—å¹²å‡€"
- 9.2ï¼šè¯åµŒå…¥ â†’ ç»™æ¯ä¸ªè¯åˆ†é…"åæ ‡"
- 9.3ï¼šRNN/LSTM/GRU â†’ å­¦ä¼šç†è§£"å¥å­"

ç°åœ¨æ˜¯æ—¶å€™æŠŠè¿™äº›å·¥å…·ç»„åˆèµ·æ¥ï¼Œè§£å†³ä¸€ä¸ªçœŸå®é—®é¢˜äº†ï¼æœ¬èŠ‚å°†æ„å»ºä¸€ä¸ªå®Œæ•´çš„æƒ…æ„Ÿåˆ†æç³»ç»Ÿã€‚

```mermaid
graph LR
    A[åŸå§‹æ–‡æœ¬] --> B[é¢„å¤„ç†]
    B --> C[è¯åµŒå…¥]
    C --> D[LSTMæ¨¡å‹]
    D --> E[æƒ…æ„Ÿåˆ†ç±»]
    E --> F[æ­£é¢/è´Ÿé¢]
```

## 9.4.1 æƒ…æ„Ÿåˆ†æä»»åŠ¡ä»‹ç»

### æŠ€æœ¯åŸç†ï¼šåƒ"è¯»è¯„ä»·"ä¸€æ ·åˆ¤æ–­æƒ…æ„Ÿ

**ä»€ä¹ˆæ˜¯æƒ…æ„Ÿåˆ†æï¼Ÿ**

æƒ³è±¡ä½ åœ¨ç½‘è´­å¹³å°ä¹°ä¸œè¥¿ï¼Œçœ‹åˆ°ä»¥ä¸‹è¯„ä»·ï¼š

```
è¯„ä»·1ï¼š"è´¨é‡å¾ˆå¥½ï¼Œéå¸¸æ»¡æ„ï¼" â†’ ä½ çš„åˆ¤æ–­ï¼šå¥½è¯„ âœ“
è¯„ä»·2ï¼š"å¤ªå·®åŠ²äº†ï¼Œå¼ºçƒˆä¸æ¨èã€‚" â†’ ä½ çš„åˆ¤æ–­ï¼šå·®è¯„ âœ—
è¯„ä»·3ï¼š"å°ºå¯¸åˆé€‚ï¼Œä»·æ ¼ä¹Ÿè¿˜å¯ä»¥ã€‚" â†’ ä½ çš„åˆ¤æ–­ï¼šä¸­æ€§
```

æƒ…æ„Ÿåˆ†æå°±æ˜¯è®©è®¡ç®—æœºåƒä½ ä¸€æ ·åˆ¤æ–­è¿™äº›è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘ã€‚

**ä»»åŠ¡ç‰¹ç‚¹ï¼š**

1. **å…¸å‹åˆ†ç±»é—®é¢˜**ï¼š
   - äºŒåˆ†ç±»ï¼šæ­£é¢ vs è´Ÿé¢
   - å¤šåˆ†ç±»ï¼šæ­£é¢/ä¸­æ€§/è´Ÿé¢
   - ç»†ç²’åº¦ï¼š1æ˜Ÿ-5æ˜Ÿè¯„åˆ†

2. **å®é™…åº”ç”¨å¹¿æ³›**ï¼š
   - ç”µå•†è¯„ä»·åˆ†æï¼šåˆ¤æ–­äº§å“å£ç¢‘
   - ç¤¾äº¤åª’ä½“ç›‘æ§ï¼šåˆ†æå…¬ä¼—æƒ…ç»ª
   - å½±è§†è¯„è®ºåˆ†æï¼šé¢„æµ‹ç¥¨æˆ¿èµ°åŠ¿
   - èˆæƒ…ç›‘æµ‹ï¼šåŠæ—¶å‘ç°è´Ÿé¢èˆ†æƒ…

**æŒ‘æˆ˜æ‰€åœ¨ï¼š**

- **è¯­ä¹‰ç†è§£**ï¼š"è¿™éƒ¨ç”µå½±ä¸å¥½çœ‹" vs "è¿™éƒ¨ç”µå½±ä¸æ˜¯ä¸å¥½çœ‹" (åŒé‡å¦å®š)
- **ä¸Šä¸‹æ–‡ä¾èµ–**ï¼š"å¼€å¤´å¾ˆå¥½ï¼Œä½†æ˜¯ç»“å°¾å¤ªçƒ‚äº†" (è½¬æŠ˜å…³ç³»)
- **è¯æ±‡æ­§ä¹‰**ï¼š"è¿™ä»·æ ¼ä¹Ÿæ˜¯æ²¡è°äº†" (åè®½)

### ç¤ºä¾‹æ•°æ®é›†

TinyAIæä¾›äº†ä¸€ä¸ªç®€åŒ–çš„ç”µå½±è¯„è®ºæ•°æ®é›†ï¼š

```java
// åˆ›å»ºç¤ºä¾‹æ•°æ®é›†
SentimentDataset dataset = SentimentDataset.createSampleDataset();

// æ­£é¢æ ·æœ¬ç¤ºä¾‹ï¼š
// "è¿™éƒ¨ç”µå½±éå¸¸å¥½çœ‹ï¼Œå¼ºçƒˆæ¨èï¼" -> æ ‡ç­¾: 1 (æ­£é¢)
// "å¾ˆä¸é”™çš„ç”µå½±ï¼Œå€¼å¾—ä¸€çœ‹ã€‚" -> æ ‡ç­¾: 1

// è´Ÿé¢æ ·æœ¬ç¤ºä¾‹ï¼š  
// "è¿™éƒ¨ç”µå½±å¤ªç³Ÿç³•äº†ï¼Œæµªè´¹æ—¶é—´ã€‚" -> æ ‡ç­¾: 0 (è´Ÿé¢)
// "ä¸æ¨èè¿™éƒ¨ç”µå½±ï¼Œå¾ˆå¤±æœ›ã€‚" -> æ ‡ç­¾: 0
```

**æ•°æ®é›†ç»“æ„ï¼š**
- æ–‡æœ¬åˆ—è¡¨ï¼šå­˜å‚¨åŸå§‹è¯„è®º
- æ ‡ç­¾åˆ—è¡¨ï¼š0(è´Ÿé¢) æˆ– 1(æ­£é¢)
- è¯æ±‡è¡¨ï¼šç”¨äºè¯æ±‡ç¼–ç 
- åˆ†è¯å™¨ï¼šç”¨äºæ–‡æœ¬åˆ†è¯

```java
/**
 * æƒ…æ„Ÿåˆ†ææ•°æ®é›†ç±»
 */
public class SentimentDataset {
    private List<String> texts;      // æ–‡æœ¬æ•°æ®
    private List<Integer> labels;    // æ ‡ç­¾æ•°æ®ï¼ˆ0-è´Ÿé¢ï¼Œ1-æ­£é¢ï¼‰
    private Vocabulary vocabulary;   // è¯æ±‡è¡¨
    private ChineseTokenizer tokenizer; // åˆ†è¯å™¨
    
    /**
     * æ„é€ å‡½æ•°
     */
    public SentimentDataset(Vocabulary vocabulary, ChineseTokenizer tokenizer) {
        this.texts = new ArrayList<>();
        this.labels = new ArrayList<>();
        this.vocabulary = vocabulary;
        this.tokenizer = tokenizer;
    }
    
    /**
     * æ·»åŠ æ•°æ®æ ·æœ¬
     */
    public void addSample(String text, int label) {
        texts.add(text);
        labels.add(label);
    }
    
    /**
     * è·å–æ•°æ®é›†å¤§å°
     */
    public int size() {
        return texts.size();
    }
    
    /**
     * è·å–æŒ‡å®šç´¢å¼•çš„æ–‡æœ¬
     */
    public String getText(int index) {
        return texts.get(index);
    }
    
    /**
     * è·å–æŒ‡å®šç´¢å¼•çš„æ ‡ç­¾
     */
    public int getLabel(int index) {
        return labels.get(index);
    }
    
    /**
     * åˆ›å»ºç¤ºä¾‹æ•°æ®é›†
     */
    public static SentimentDataset createSampleDataset() {
        // åˆ›å»ºè¯æ±‡è¡¨å’Œåˆ†è¯å™¨
        Set<String> dictionary = new HashSet<>(Arrays.asList(
            "è¿™ä¸ª", "ç”µå½±", "éå¸¸", "å¥½çœ‹", "ä¸é”™", "å–œæ¬¢", "æ¨è", "ç²¾å½©",
            "å¾ˆ", "ä¸", "å·®", "ç³Ÿç³•", "è®¨åŒ", "æµªè´¹", "æ—¶é—´", "æ— èŠ",
            "æ¼”å‘˜", "è¡¨æ¼”", "å‰§æƒ…", "ç‰¹æ•ˆ", "ç”»é¢", "éŸ³ä¹", "å¯¼æ¼”",
            "è‡ªç„¶è¯­è¨€", "å¤„ç†", "æŠ€æœ¯", "é‡è¦", "äººå·¥æ™ºèƒ½"
        ));
        
        Vocabulary vocabulary = new Vocabulary();
        ChineseTokenizer tokenizer = new ChineseTokenizer(dictionary);
        
        // æ„å»ºè¯æ±‡è¡¨
        vocabulary.addTokens(new ArrayList<>(dictionary));
        
        SentimentDataset dataset = new SentimentDataset(vocabulary, tokenizer);
        
        // æ·»åŠ æ­£é¢æ ·æœ¬
        dataset.addSample("è¿™éƒ¨ç”µå½±éå¸¸å¥½çœ‹ï¼Œå¼ºçƒˆæ¨èï¼", 1);
        dataset.addSample("å¾ˆä¸é”™çš„ç”µå½±ï¼Œå€¼å¾—ä¸€çœ‹ã€‚", 1);
        dataset.addSample("æ¼”å‘˜è¡¨æ¼”ç²¾å½©ï¼Œå‰§æƒ…å¼•äººå…¥èƒœã€‚", 1);
        dataset.addSample("ç‰¹æ•ˆå¾ˆæ£’ï¼Œç”»é¢ç²¾ç¾ã€‚", 1);
        dataset.addSample("å¯¼æ¼”åŠŸåŠ›æ·±åšï¼Œè¿™éƒ¨ç”µå½±å¾ˆç²¾å½©ã€‚", 1);
        dataset.addSample("éŸ³ä¹é…åˆå¾—å¾ˆå¥½ï¼Œå¢å¼ºäº†è§‚å½±ä½“éªŒã€‚", 1);
        dataset.addSample("æ•…äº‹æƒ…èŠ‚ç´§å‡‘ï¼Œè®©äººæ¬²ç½¢ä¸èƒ½ã€‚", 1);
        dataset.addSample("è¿™éƒ¨å½±ç‰‡åœ¨å„ä¸ªæ–¹é¢éƒ½è¡¨ç°å‡ºè‰²ã€‚", 1);
        
        // æ·»åŠ è´Ÿé¢æ ·æœ¬
        dataset.addSample("è¿™éƒ¨ç”µå½±å¤ªç³Ÿç³•äº†ï¼Œæµªè´¹æ—¶é—´ã€‚", 0);
        dataset.addSample("ä¸æ¨èè¿™éƒ¨ç”µå½±ï¼Œå¾ˆå¤±æœ›ã€‚", 0);
        dataset.addSample("æ¼”å‘˜è¡¨æ¼”ç”Ÿç¡¬ï¼Œå‰§æƒ…æ— èŠã€‚", 0);
        dataset.addSample("ç‰¹æ•ˆç²—ç³™ï¼Œç”»é¢æ¨¡ç³Šã€‚", 0);
        dataset.addSample("å¯¼æ¼”æ°´å¹³æœ‰é™ï¼Œè¿™éƒ¨ç”µå½±å¾ˆå¤±è´¥ã€‚", 0);
        dataset.addSample("éŸ³ä¹ä¸å‰§æƒ…ä¸æ­ï¼Œç ´åäº†æ•´ä½“æ•ˆæœã€‚", 0);
        dataset.addSample("æ•…äº‹æƒ…èŠ‚æ‹–æ²“ï¼Œè®©äººæ˜æ˜æ¬²ç¡ã€‚", 0);
        dataset.addSample("è¿™éƒ¨å½±ç‰‡åœ¨å„ä¸ªæ–¹é¢éƒ½å¾ˆå·®åŠ²ã€‚", 0);
        
        return dataset;
    }
    
    // Getteræ–¹æ³•
    public Vocabulary getVocabulary() { return vocabulary; }
    public ChineseTokenizer getTokenizer() { return tokenizer; }
}
```

## 9.4.2 æ•°æ®é¢„å¤„ç†æµæ°´çº¿

### æŠ€æœ¯åŸç†ï¼šåƒ"æµæ°´çº¿"ä¸€æ ·å¤„ç†æ•°æ®

æ•°æ®é¢„å¤„ç†å°±åƒå·¥å‚æµæ°´çº¿ï¼ŒåŸææ–™(åŸå§‹æ–‡æœ¬)ç»è¿‡å¤šä¸ªå·¥ä½åŠ å·¥ï¼Œæœ€ç»ˆå˜æˆæˆå“(æ•°å€¼åºåˆ—):

```mermaid
graph LR
    A[åŸå§‹æ–‡æœ¬] --> B[æ¸…æ´—å·¥ä½]
    B --> C[åˆ†è¯å·¥ä½]
    C --> D[åŠ æ ‡è®°å·¥ä½]
    D --> E[ç¼–ç å·¥ä½]
    E --> F[å¡«å……å·¥ä½]
    F --> G[æ•°å€¼åºåˆ—]
```

**å¤„ç†æµç¨‹ç¤ºä¾‹ï¼š**

```
è¾“å…¥: "è¿™éƒ¨ç”µå½±å¾ˆå¥½çœ‹ï¼"
  â†“ æ­¥éª¤1: æ¸…æ´—
"è¿™éƒ¨ç”µå½±å¾ˆå¥½çœ‹"  (å»é™¤æ ‡ç‚¹)
  â†“ æ­¥éª¤2: åˆ†è¯
["è¿™éƒ¨", "ç”µå½±", "å¾ˆ", "å¥½çœ‹"]
  â†“ æ­¥éª¤3: åŠ æ ‡è®°
["<SOS>", "è¿™éƒ¨", "ç”µå½±", "å¾ˆ", "å¥½çœ‹", "<EOS>"]
  â†“ æ­¥éª¤4: è½¬ç´¢å¼•
[2, 45, 78, 12, 23, 3]
  â†“ æ­¥éª¤5: å¡«å……åˆ°20ä¸ªå…ƒç´ 
[2, 45, 78, 12, 23, 3, 0, 0, 0, ..., 0]
  â†“
è¾“å‡º: æ•°å€¼åºåˆ— (æ¨¡å‹è¾“å…¥)
```

**TinyAIçš„é¢„å¤„ç†å™¨ï¼š**

```java
// åˆ›å»ºé¢„å¤„ç†å™¨
SentimentDataPreprocessor preprocessor = new SentimentDataPreprocessor(
    vocabulary, tokenizer, maxLength=20
);

// å•æ¡æ–‡æœ¬å¤„ç†
int[] sequence = preprocessor.preprocessText("è¿™éƒ¨ç”µå½±å¾ˆå¥½çœ‹");

// æ‰¹é‡å¤„ç†
ProcessedDataset processed = preprocessor.preprocessDataset(dataset);
```

```java
/**
 * æƒ…æ„Ÿåˆ†ææ•°æ®é¢„å¤„ç†å™¨
 */
public class SentimentDataPreprocessor {
    private Vocabulary vocabulary;
    private ChineseTokenizer tokenizer;
    private int maxLength;
    private int padIndex;
    
    /**
     * æ„é€ å‡½æ•°
     */
    public SentimentDataPreprocessor(Vocabulary vocabulary, 
                                   ChineseTokenizer tokenizer, 
                                   int maxLength) {
        this.vocabulary = vocabulary;
        this.tokenizer = tokenizer;
        this.maxLength = maxLength;
        this.padIndex = vocabulary.getPadIndex();
    }
    
    /**
     * é¢„å¤„ç†å•ä¸ªæ–‡æœ¬
     */
    public int[] preprocessText(String text) {
        // 1. æ–‡æœ¬æ¸…æ´—
        String cleaned = TextCleaner.cleanText(text);
        String normalized = TextCleaner.normalizeText(cleaned);
        
        // 2. åˆ†è¯
        List<String> tokens = tokenizer.forwardMaxMatch(normalized);
        
        // 3. æ·»åŠ å¥å­è¾¹ç•Œæ ‡è®°
        tokens.add(0, Vocabulary.SOS_TOKEN);
        tokens.add(Vocabulary.EOS_TOKEN);
        
        // 4. è½¬æ¢ä¸ºç´¢å¼•åºåˆ—
        List<Integer> indices = tokens.stream()
                .map(vocabulary::getIndex)
                .collect(Collectors.toList());
        
        // 5. å¡«å……æˆ–æˆªæ–­
        List<Integer> processed = SequenceProcessor.padOrTruncate(
                indices, maxLength, padIndex, false);
        
        // 6. è½¬æ¢ä¸ºæ•°ç»„
        return processed.stream().mapToInt(Integer::intValue).toArray();
    }
    
    /**
     * æ‰¹é‡é¢„å¤„ç†æ–‡æœ¬
     */
    public int[][] preprocessBatch(List<String> texts) {
        return texts.stream()
                .map(this::preprocessText)
                .toArray(int[][]::new);
    }
    
    /**
     * é¢„å¤„ç†æ•°æ®é›†
     */
    public ProcessedDataset preprocessDataset(SentimentDataset dataset) {
        int size = dataset.size();
        int[][] features = new int[size][];
        int[] labels = new int[size];
        
        for (int i = 0; i < size; i++) {
            features[i] = preprocessText(dataset.getText(i));
            labels[i] = dataset.getLabel(i);
        }
        
        return new ProcessedDataset(features, labels);
    }
    
    /**
     * æ•°æ®é›†åˆ’åˆ†
     */
    public DatasetSplit splitDataset(ProcessedDataset dataset, double trainRatio) {
        int size = dataset.size();
        int trainSize = (int) (size * trainRatio);
        
        // ç®€å•çš„éšæœºåˆ’åˆ†ï¼ˆå®é™…åº”ç”¨ä¸­åº”è¯¥æ›´å¤æ‚ï¼‰
        int[][] allFeatures = dataset.getFeatures();
        int[] allLabels = dataset.getLabels();
        
        int[][] trainFeatures = Arrays.copyOfRange(allFeatures, 0, trainSize);
        int[] trainLabels = Arrays.copyOfRange(allLabels, 0, trainSize);
        
        int[][] testFeatures = Arrays.copyOfRange(allFeatures, trainSize, size);
        int[] testLabels = Arrays.copyOfRange(allLabels, trainSize, size);
        
        return new DatasetSplit(
            new ProcessedDataset(trainFeatures, trainLabels),
            new ProcessedDataset(testFeatures, testLabels)
        );
    }
}

/**
 * é¢„å¤„ç†åçš„æ•°æ®é›†
 */
class ProcessedDataset {
    private int[][] features;
    private int[] labels;
    
    public ProcessedDataset(int[][] features, int[] labels) {
        this.features = features;
        this.labels = labels;
    }
    
    public int size() {
        return features.length;
    }
    
    // Getteræ–¹æ³•
    public int[][] getFeatures() { return features; }
    public int[] getLabels() { return labels; }
}

/**
 * æ•°æ®é›†åˆ’åˆ†ç»“æœ
 */
class DatasetSplit {
    private ProcessedDataset trainDataset;
    private ProcessedDataset testDataset;
    
    public DatasetSplit(ProcessedDataset trainDataset, ProcessedDataset testDataset) {
        this.trainDataset = trainDataset;
        this.testDataset = testDataset;
    }
    
    // Getteræ–¹æ³•
    public ProcessedDataset getTrainDataset() { return trainDataset; }
    public ProcessedDataset getTestDataset() { return testDataset; }
}
```

## 9.4.3 æƒ…æ„Ÿåˆ†ææ¨¡å‹å®ç°

### æŠ€æœ¯åŸç†:åƒ"è¯„å§”æ‰“åˆ†"ä¸€æ ·åˆ†ç±»

**æ¨¡å‹æ¶æ„è®¾è®¡:**

æƒ³è±¡ä¸€ä¸ªè¯„å§”ç»™ç”µå½±æ‰“åˆ†çš„è¿‡ç¨‹:

```mermaid
graph TD
    A[åŸå§‹è¯„è®º] --> B[è¯åµŒå…¥å±‚]
    B --> C[LSTMå¤„ç†å±‚]
    C --> D[åˆ†ç±»å±‚]
    D --> E[æ‰“åˆ†ç»“æœ]
    
    B1["å°†è¯è½¬ä¸ºå‘é‡"] -.-> B
    C1["ç†è§£å¥å­å«ä¹‰"] -.-> C
    D1["åˆ¤æ–­æ­£è´Ÿé¢"] -.-> D
```

1. **è¯åµŒå…¥å±‚**:æŠŠæ¯ä¸ªè¯è½¬æ¢ä¸ºå‘é‡
   - å°±åƒè¯„å§”å…ˆäº†è§£æ¯ä¸ªè¯çš„å«ä¹‰
   - "å¥½çœ‹" â†’ [0.8, 0.9, ...]
   - "ç³Ÿç³•" â†’ [-0.7, -0.8, ...]

2. **LSTMå¤„ç†å±‚**:ç†è§£æ•´å¥è¯çš„æ„æ€
   - å°±åƒè¯„å§”ç†è§£å¥å­çš„å‰åå…³ç³»
   - "è™½ç„¶å¼€å¤´ä¸é”™,ä½†æ˜¯ç»“å±€å¤ªçƒ‚äº†" â†’ æ•´ä½“åè´Ÿé¢

3. **åˆ†ç±»å±‚**:åšå‡ºæœ€ç»ˆåˆ¤æ–­
   - å°±åƒè¯„å§”ç»™å‡ºæœ€ç»ˆæ‰“åˆ†
   - è¾“å‡º:[æ­£é¢æ¦‚ç‡:0.2, è´Ÿé¢æ¦‚ç‡:0.8] â†’ åˆ¤å®šä¸ºè´Ÿé¢

**TinyAIå®ç°:**

```java
// åˆ›å»ºæ¨¡å‹
SentimentAnalysisModel model = new SentimentAnalysisModel(
    vocabSize=1000,      // è¯æ±‡è¡¨å¤§å°
    embeddingDim=100,    // è¯å‘é‡ç»´åº¦  
    hiddenSize=128,      // LSTMéšè—å±‚å¤§å°
    numClasses=2         // åˆ†ç±»æ•°(æ­£/è´Ÿ)
);

// é¢„æµ‹å•æ¡è¯„è®º
int[] sequence = preprocessor.preprocessText("è¿™éƒ¨ç”µå½±å¾ˆå¥½çœ‹");
SentimentOutput result = model.forward(sequence);

System.out.println("é¢„æµ‹ç±»åˆ«: " + (result.getPredictedClass() == 1 ? "æ­£é¢" : "è´Ÿé¢"));
System.out.println("æ­£é¢æ¦‚ç‡: " + result.getProbabilities()[1]);
System.out.println("è´Ÿé¢æ¦‚ç‡: " + result.getProbabilities()[0]);
```

**å…³é”®ç»„ä»¶:**
- è¯åµŒå…¥çŸ©é˜µ:å°†è¯ç´¢å¼•è½¬ä¸ºå‘é‡
- LSTMç½‘ç»œ:æ•æ‰åºåˆ—ä¿¡æ¯
- Softmaxå±‚:è¾“å‡ºæ¦‚ç‡åˆ†å¸ƒ

```java
/**
 * æƒ…æ„Ÿåˆ†ææ¨¡å‹
 */
public class SentimentAnalysisModel {
    private LSTM lstm;
    private int vocabSize;
    private int embeddingDim;
    private int hiddenSize;
    private int numClasses;
    
    // è¯åµŒå…¥çŸ©é˜µ
    private double[][] embeddings;
    
    /**
     * æ„é€ å‡½æ•°
     */
    public SentimentAnalysisModel(int vocabSize, int embeddingDim, 
                                int hiddenSize, int numClasses) {
        this.vocabSize = vocabSize;
        this.embeddingDim = embeddingDim;
        this.hiddenSize = hiddenSize;
        this.numClasses = numClasses;
        
        // åˆå§‹åŒ–LSTM
        this.lstm = new LSTM(embeddingDim, hiddenSize, numClasses);
        
        // åˆå§‹åŒ–è¯åµŒå…¥çŸ©é˜µ
        this.embeddings = initializeEmbeddings();
    }
    
    /**
     * åˆå§‹åŒ–è¯åµŒå…¥çŸ©é˜µ
     */
    private double[][] initializeEmbeddings() {
        double[][] embeds = new double[vocabSize][embeddingDim];
        Random random = new Random(42);
        
        // Xavieråˆå§‹åŒ–
        double scale = Math.sqrt(6.0 / (vocabSize + embeddingDim));
        for (int i = 0; i < vocabSize; i++) {
            for (int j = 0; j < embeddingDim; j++) {
                embeds[i][j] = (random.nextDouble() * 2 - 1) * scale;
            }
        }
        
        return embeds;
    }
    
    /**
     * å°†ç´¢å¼•åºåˆ—è½¬æ¢ä¸ºè¯åµŒå…¥åºåˆ—
     */
    private double[][] indicesToEmbeddings(int[] indices) {
        double[][] embeddingsSeq = new double[indices.length][embeddingDim];
        
        for (int i = 0; i < indices.length; i++) {
            int index = indices[i];
            if (index >= 0 && index < vocabSize) {
                System.arraycopy(this.embeddings[index], 0, 
                               embeddingsSeq[i], 0, embeddingDim);
            }
        }
        
        return embeddingsSeq;
    }
    
    /**
     * å‰å‘ä¼ æ’­
     */
    public SentimentOutput forward(int[] inputIndices) {
        // 1. è½¬æ¢ä¸ºè¯åµŒå…¥åºåˆ—
        double[][] embeddingsSeq = indicesToEmbeddings(inputIndices);
        
        // 2. LSTMå¤„ç†
        LSTMOutput lstmOutput = lstm.forward(embeddingsSeq);
        double[][] outputs = lstmOutput.getOutputs();
        
        // 3. å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºä½œä¸ºåˆ†ç±»ç»“æœ
        double[] finalOutput = outputs[outputs.length - 1];
        
        // 4. åº”ç”¨softmaxè·å–æ¦‚ç‡åˆ†å¸ƒ
        double[] probabilities = softmax(finalOutput);
        
        // 5. é¢„æµ‹ç±»åˆ«
        int predictedClass = argmax(probabilities);
        
        return new SentimentOutput(predictedClass, probabilities, finalOutput);
    }
    
    /**
     * è®¡ç®—Softmax
     */
    private double[] softmax(double[] logits) {
        double[] probs = new double[logits.length];
        double maxLogit = Arrays.stream(logits).max().orElse(0);
        double sumExp = 0;
        
        // æ•°å€¼ç¨³å®šæ€§å¤„ç†
        for (int i = 0; i < logits.length; i++) {
            probs[i] = Math.exp(logits[i] - maxLogit);
            sumExp += probs[i];
        }
        
        // å½’ä¸€åŒ–
        for (int i = 0; i < probs.length; i++) {
            probs[i] /= sumExp;
        }
        
        return probs;
    }
    
    /**
     * è·å–æœ€å¤§å€¼ç´¢å¼•
     */
    private int argmax(double[] array) {
        int maxIndex = 0;
        for (int i = 1; i < array.length; i++) {
            if (array[i] > array[maxIndex]) {
                maxIndex = i;
            }
        }
        return maxIndex;
    }
    
    /**
     * è®¡ç®—æŸå¤±ï¼ˆäº¤å‰ç†µï¼‰
     */
    public double computeLoss(int[] inputIndices, int trueLabel) {
        SentimentOutput output = forward(inputIndices);
        double[] logits = output.getLogits();
        
        // è®¡ç®—äº¤å‰ç†µæŸå¤±
        double loss = -Math.log(Math.max(softmax(logits)[trueLabel], 1e-10));
        return loss;
    }
    
    /**
     * æ‰¹é‡é¢„æµ‹
     */
    public int[] predictBatch(int[][] inputIndicesBatch) {
        int[] predictions = new int[inputIndicesBatch.length];
        
        for (int i = 0; i < inputIndicesBatch.length; i++) {
            SentimentOutput output = forward(inputIndicesBatch[i]);
            predictions[i] = output.getPredictedClass();
        }
        
        return predictions;
    }
    
    /**
     * è¯„ä¼°æ¨¡å‹
     */
    public EvaluationResult evaluate(int[][] features, int[] labels) {
        int correct = 0;
        int total = features.length;
        
        for (int i = 0; i < total; i++) {
            SentimentOutput output = forward(features[i]);
            if (output.getPredictedClass() == labels[i]) {
                correct++;
            }
        }
        
        double accuracy = (double) correct / total;
        return new EvaluationResult(accuracy, correct, total);
    }
    
    // Getterå’ŒSetteræ–¹æ³•
    public double[][] getEmbeddings() { return embeddings; }
    public void setEmbeddings(double[][] embeddings) { this.embeddings = embeddings; }
}

/**
 * æƒ…æ„Ÿåˆ†æè¾“å‡ºç»“æœ
 */
class SentimentOutput {
    private int predictedClass;
    private double[] probabilities;
    private double[] logits;
    
    public SentimentOutput(int predictedClass, double[] probabilities, double[] logits) {
        this.predictedClass = predictedClass;
        this.probabilities = probabilities;
        this.logits = logits;
    }
    
    // Getteræ–¹æ³•
    public int getPredictedClass() { return predictedClass; }
    public double[] getProbabilities() { return probabilities; }
    public double[] getLogits() { return logits; }
}

/**
 * è¯„ä¼°ç»“æœ
 */
class EvaluationResult {
    private double accuracy;
    private int correct;
    private int total;
    
    public EvaluationResult(double accuracy, int correct, int total) {
        this.accuracy = accuracy;
        this.correct = correct;
        this.total = total;
    }
    
    @Override
    public String toString() {
        return String.format("å‡†ç¡®ç‡: %.2f%% (%d/%d)", accuracy * 100, correct, total);
    }
    
    // Getteræ–¹æ³•
    public double getAccuracy() { return accuracy; }
    public int getCorrect() { return correct; }
    public int getTotal() { return total; }
}
```

## 9.4.4 è®­ç»ƒæµç¨‹å®ç°

### æŠ€æœ¯åŸç†:åƒ"ç»ƒä¹ é¢˜"ä¸€æ ·è®­ç»ƒæ¨¡å‹

**è®­ç»ƒè¿‡ç¨‹ç±»æ¯”:**

å­¦ç”Ÿåšç»ƒä¹ é¢˜çš„è¿‡ç¨‹:
```
1. çœ‹é¢˜ç›® â†’ æ¨¡å‹çœ‹è®­ç»ƒæ•°æ®
2. ç»™ç­”æ¡ˆ â†’ æ¨¡å‹é¢„æµ‹ç»“æœ
3. å¯¹ç­”æ¡ˆ â†’ è®¡ç®—é¢„æµ‹è¯¯å·®
4. æ€»ç»“é”™è¯¯ â†’ åå‘ä¼ æ’­æ›´æ–°å‚æ•°
5. åå¤ç»ƒä¹  â†’ å¤šè½®è®­ç»ƒ(Epochs)
```

**è®­ç»ƒæµç¨‹:**

```mermaid
graph TD
    A[å‡†å¤‡æ•°æ®] --> B[åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†]
    B --> C[å¼€å§‹è®­ç»ƒ]
    C --> D[å‰å‘ä¼ æ’­]
    D --> E[è®¡ç®—æŸå¤±]
    E --> F[åå‘ä¼ æ’­]
    F --> G[æ›´æ–°å‚æ•°]
    G --> H{è¿˜æœ‰æ•°æ®?}
    H -->|æ˜¯| D
    H -->|å¦| I{è¾¾åˆ°Epochs?}
    I -->|å¦| C
    I -->|æ˜¯| J[è¯„ä¼°æ¨¡å‹]
    J --> K[ä¿å­˜æ¨¡å‹]
```

**å®Œæ•´è®­ç»ƒç¤ºä¾‹:**

```java
public class SentimentTrainingExample {
    public static void main(String[] args) {
        // 1. å‡†å¤‡æ•°æ®
        SentimentDataset dataset = SentimentDataset.createSampleDataset();
        SentimentDataPreprocessor preprocessor = new SentimentDataPreprocessor(
            dataset.getVocabulary(), dataset.getTokenizer(), maxLength=20
        );
        
        // 2. é¢„å¤„ç†å’Œåˆ’åˆ†æ•°æ®
        ProcessedDataset processed = preprocessor.preprocessDataset(dataset);
        DatasetSplit split = preprocessor.splitDataset(processed, trainRatio=0.8);
        
        // 3. åˆ›å»ºæ¨¡å‹
        SentimentAnalysisModel model = new SentimentAnalysisModel(
            vocabSize=1000, embeddingDim=100, hiddenSize=128, numClasses=2
        );
        
        // 4. è®­ç»ƒæ¨¡å‹
        int epochs = 50;
        for (int epoch = 0; epoch < epochs; epoch++) {
            double totalLoss = 0;
            int[][] trainFeatures = split.getTrainDataset().getFeatures();
            int[] trainLabels = split.getTrainDataset().getLabels();
            
            // éå†è®­ç»ƒæ•°æ®
            for (int i = 0; i < trainFeatures.length; i++) {
                // å‰å‘ä¼ æ’­
                double loss = model.computeLoss(trainFeatures[i], trainLabels[i]);
                totalLoss += loss;
                
                // åå‘ä¼ æ’­(ç®€åŒ–,å®é™…éœ€è¦å®Œæ•´å®ç°)
                // model.backward(...);
            }
            
            // æ¯10è½®è¯„ä¼°ä¸€æ¬¡
            if (epoch % 10 == 0) {
                EvaluationResult result = model.evaluate(
                    split.getTestDataset().getFeatures(),
                    split.getTestDataset().getLabels()
                );
                System.out.printf("Epoch %d: Loss=%.4f, %s%n", 
                    epoch, totalLoss/trainFeatures.length, result);
            }
        }
        
        // 5. æµ‹è¯•é¢„æµ‹
        String testText = "è¿™éƒ¨ç”µå½±éå¸¸ç²¾å½©,å¼ºçƒˆæ¨è!";
        int[] sequence = preprocessor.preprocessText(testText);
        SentimentOutput result = model.forward(sequence);
        
        System.out.println("\næµ‹è¯•æ–‡æœ¬: " + testText);
        System.out.println("é¢„æµ‹ç»“æœ: " + 
            (result.getPredictedClass() == 1 ? "æ­£é¢ğŸ˜Š" : "è´Ÿé¢ğŸ˜"));
        System.out.printf("ç½®ä¿¡åº¦: %.2f%%\n", 
            result.getProbabilities()[result.getPredictedClass()] * 100);
    }
}
```

**è®­ç»ƒæŠ€å·§:**

1. **æ•°æ®åˆ’åˆ†**:80%è®­ç»ƒ,20%æµ‹è¯•
2. **æ‰¹é‡è®­ç»ƒ**:æ¯æ¬¡å¤„ç†å¤šä¸ªæ ·æœ¬,æé«˜æ•ˆç‡
3. **å­¦ä¹ ç‡è°ƒæ•´**:å¼€å§‹å¤§ä¸€ç‚¹(0.01),åæœŸå°ä¸€ç‚¹(0.001)
4. **æ—©åœæ³•**:æµ‹è¯•å‡†ç¡®ç‡ä¸å†æå‡æ—¶åœæ­¢è®­ç»ƒ
5. **æ­£åˆ™åŒ–**:é˜²æ­¢è¿‡æ‹Ÿåˆ

```java
/**
 * æƒ…æ„Ÿåˆ†æè®­ç»ƒå™¨
 */
public class SentimentTrainer {
    private SentimentAnalysisModel model;
    private SentimentDataPreprocessor preprocessor;
    private double learningRate;
    private int batchSize;
    
    /**
     * æ„é€ å‡½æ•°
     */
    public SentimentTrainer(SentimentAnalysisModel model, 
                          SentimentDataPreprocessor preprocessor,
                          double learningRate, int batchSize) {
        this.model = model;
        this.preprocessor = preprocessor;
        this.learningRate = learningRate;
        this.batchSize = batchSize;
    }
    
    /**
     * è®­ç»ƒæ¨¡å‹
     */
    public TrainingHistory train(ProcessedDataset trainDataset, 
                               ProcessedDataset validationDataset,
                               int epochs) {
        TrainingHistory history = new TrainingHistory();
        
        System.out.println("å¼€å§‹è®­ç»ƒæƒ…æ„Ÿåˆ†ææ¨¡å‹...");
        System.out.println("è®­ç»ƒæ ·æœ¬æ•°: " + trainDataset.size());
        System.out.println("éªŒè¯æ ·æœ¬æ•°: " + validationDataset.size());
        System.out.println("æ‰¹æ¬¡å¤§å°: " + batchSize);
        System.out.println("å­¦ä¹ ç‡: " + learningRate);
        System.out.println("è®­ç»ƒè½®æ•°: " + epochs);
        System.out.println("------------------------");
        
        for (int epoch = 0; epoch < epochs; epoch++) {
            // è®­ç»ƒä¸€ä¸ªepoch
            double trainLoss = trainEpoch(trainDataset);
            
            // éªŒè¯
            EvaluationResult trainEval = model.evaluate(
                trainDataset.getFeatures(), trainDataset.getLabels());
            EvaluationResult valEval = model.evaluate(
                validationDataset.getFeatures(), validationDataset.getLabels());
            
            // è®°å½•å†å²
            history.addRecord(epoch, trainLoss, trainEval.getAccuracy(), valEval.getAccuracy());
            
            // æ‰“å°è¿›åº¦
            if (epoch % 10 == 0 || epoch == epochs - 1) {
                System.out.printf("Epoch %d: è®­ç»ƒæŸå¤±=%.4f, è®­ç»ƒå‡†ç¡®ç‡=%s, éªŒè¯å‡†ç¡®ç‡=%s%n",
                    epoch, trainLoss, trainEval, valEval);
            }
        }
        
        System.out.println("è®­ç»ƒå®Œæˆï¼");
        return history;
    }
    
    /**
     * è®­ç»ƒä¸€ä¸ªepoch
     */
    private double trainEpoch(ProcessedDataset dataset) {
        int[][] features = dataset.getFeatures();
        int[] labels = dataset.getLabels();
        int size = dataset.size();
        
        double totalLoss = 0;
        int batches = (size + batchSize - 1) / batchSize;
        
        for (int batch = 0; batch < batches; batch++) {
            int start = batch * batchSize;
            int end = Math.min(start + batchSize, size);
            
            // æ‰¹é‡è®­ç»ƒï¼ˆç®€åŒ–å®ç°ï¼Œå®é™…åº”å®ç°æ¢¯åº¦ç´¯ç§¯ï¼‰
            for (int i = start; i < end; i++) {
                double loss = model.computeLoss(features[i], labels[i]);
                totalLoss += loss;
                
                // ç®€åŒ–çš„å‚æ•°æ›´æ–°ï¼ˆå®é™…åº”å®ç°å®Œæ•´çš„åå‘ä¼ æ’­ï¼‰
                // è¿™é‡Œçœç•¥å…·ä½“å®ç°ï¼Œä»…ä½œä¸ºæ¡†æ¶æ¼”ç¤º
            }
        }
        
        return totalLoss / size;
    }
    
    /**
     * é¢„æµ‹å•ä¸ªæ–‡æœ¬
     */
    public SentimentPrediction predict(String text) {
        int[] indices = preprocessor.preprocessText(text);
        SentimentOutput output = model.forward(indices);
        
        String sentiment = output.getPredictedClass() == 1 ? "æ­£é¢" : "è´Ÿé¢";
        double confidence = Arrays.stream(output.getProbabilities()).max().orElse(0);
        
        return new SentimentPrediction(sentiment, confidence, output.getProbabilities());
    }
    
    /**
     * æ‰¹é‡é¢„æµ‹
     */
    public List<SentimentPrediction> predictBatch(List<String> texts) {
        return texts.stream()
                .map(this::predict)
                .collect(Collectors.toList());
    }
}

/**
 * è®­ç»ƒå†å²è®°å½•
 */
class TrainingHistory {
    private List<EpochRecord> records;
    
    public TrainingHistory() {
        this.records = new ArrayList<>();
    }
    
    public void addRecord(int epoch, double loss, double trainAccuracy, double valAccuracy) {
        records.add(new EpochRecord(epoch, loss, trainAccuracy, valAccuracy));
    }
    
    public List<EpochRecord> getRecords() {
        return records;
    }
}

/**
 * Epochè®°å½•
 */
class EpochRecord {
    private int epoch;
    private double loss;
    private double trainAccuracy;
    private double valAccuracy;
    
    public EpochRecord(int epoch, double loss, double trainAccuracy, double valAccuracy) {
        this.epoch = epoch;
        this.loss = loss;
        this.trainAccuracy = trainAccuracy;
        this.valAccuracy = valAccuracy;
    }
    
    // Getteræ–¹æ³•
    public int getEpoch() { return epoch; }
    public double getLoss() { return loss; }
    public double getTrainAccuracy() { return trainAccuracy; }
    public double getValAccuracy() { return valAccuracy; }
}

/**
 * æƒ…æ„Ÿé¢„æµ‹ç»“æœ
 */
class SentimentPrediction {
    private String sentiment;
    private double confidence;
    private double[] probabilities;
    
    public SentimentPrediction(String sentiment, double confidence, double[] probabilities) {
        this.sentiment = sentiment;
        this.confidence = confidence;
        this.probabilities = probabilities;
    }
    
    @Override
    public String toString() {
        return String.format("æƒ…æ„Ÿ: %s (ç½®ä¿¡åº¦: %.2f%%)", sentiment, confidence * 100);
    }
    
    // Getteræ–¹æ³•
    public String getSentiment() { return sentiment; }
    public double getConfidence() { return confidence; }
    public double[] getProbabilities() { return probabilities; }
}
```

## 9.4.5 å®Œæ•´çš„æƒ…æ„Ÿåˆ†æç³»ç»Ÿ

å°†æ‰€æœ‰ç»„ä»¶æ•´åˆæˆä¸€ä¸ªå®Œæ•´çš„æƒ…æ„Ÿåˆ†æç³»ç»Ÿï¼š

```java
/**
 * å®Œæ•´çš„æƒ…æ„Ÿåˆ†æç³»ç»Ÿ
 */
public class SentimentAnalysisSystem {
    private SentimentDataset dataset;
    private SentimentDataPreprocessor preprocessor;
    private SentimentAnalysisModel model;
    private SentimentTrainer trainer;
    
    /**
     * æ„é€ å‡½æ•°
     */
    public SentimentAnalysisSystem() {
        // åˆå§‹åŒ–ç»„ä»¶
        initializeComponents();
    }
    
    /**
     * åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶
     */
    private void initializeComponents() {
        // 1. åˆ›å»ºæ•°æ®é›†
        this.dataset = SentimentDataset.createSampleDataset();
        
        // 2. åˆ›å»ºé¢„å¤„ç†å™¨
        this.preprocessor = new SentimentDataPreprocessor(
            dataset.getVocabulary(), 
            dataset.getTokenizer(), 
            20  // æœ€å¤§åºåˆ—é•¿åº¦
        );
        
        // 3. é¢„å¤„ç†æ•°æ®é›†
        ProcessedDataset processedDataset = preprocessor.preprocessDataset(dataset);
        
        // 4. åˆ’åˆ†æ•°æ®é›†
        DatasetSplit split = preprocessor.splitDataset(processedDataset, 0.8);
        
        // 5. åˆ›å»ºæ¨¡å‹
        this.model = new SentimentAnalysisModel(
            dataset.getVocabulary().size(),  // è¯æ±‡è¡¨å¤§å°
            50,   // è¯åµŒå…¥ç»´åº¦
            100,  // LSTMéšè—å±‚å¤§å°
            2     // åˆ†ç±»æ•°ï¼ˆæ­£é¢/è´Ÿé¢ï¼‰
        );
        
        // 6. åˆ›å»ºè®­ç»ƒå™¨
        this.trainer = new SentimentTrainer(
            model, 
            preprocessor, 
            0.01,  // å­¦ä¹ ç‡
            4      // æ‰¹æ¬¡å¤§å°
        );
    }
    
    /**
     * è®­ç»ƒæ¨¡å‹
     */
    public void train() {
        // é‡æ–°é¢„å¤„ç†æ•°æ®é›†
        ProcessedDataset processedDataset = preprocessor.preprocessDataset(dataset);
        DatasetSplit split = preprocessor.splitDataset(processedDataset, 0.8);
        
        // è®­ç»ƒæ¨¡å‹
        TrainingHistory history = trainer.train(
            split.getTrainDataset(),
            split.getTestDataset(),
            100  // è®­ç»ƒè½®æ•°
        );
        
        // æ˜¾ç¤ºè®­ç»ƒå†å²
        displayTrainingHistory(history);
    }
    
    /**
     * æ˜¾ç¤ºè®­ç»ƒå†å²
     */
    private void displayTrainingHistory(TrainingHistory history) {
        System.out.println("\n=== è®­ç»ƒå†å² ===");
        System.out.println("Epoch\tæŸå¤±\t\tè®­ç»ƒå‡†ç¡®ç‡\téªŒè¯å‡†ç¡®ç‡");
        System.out.println("-----\t----\t\t--------\t--------");
        
        List<EpochRecord> records = history.getRecords();
        for (int i = 0; i < records.size(); i += 10) {  // æ¯10ä¸ªepochæ˜¾ç¤ºä¸€æ¬¡
            EpochRecord record = records.get(i);
            System.out.printf("%d\t%.4f\t\t%.2f%%\t\t%.2f%%%n",
                record.getEpoch(),
                record.getLoss(),
                record.getTrainAccuracy() * 100,
                record.getValAccuracy() * 100
            );
        }
        
        // æ˜¾ç¤ºæœ€åå‡ ä¸ªepoch
        if (records.size() > 5) {
            System.out.println("...");
            for (int i = Math.max(0, records.size() - 3); i < records.size(); i++) {
                EpochRecord record = records.get(i);
                System.out.printf("%d\t%.4f\t\t%.2f%%\t\t%.2f%%%n",
                    record.getEpoch(),
                    record.getLoss(),
                    record.getTrainAccuracy() * 100,
                    record.getValAccuracy() * 100
                );
            }
        }
    }
    
    /**
     * é¢„æµ‹æ–‡æœ¬æƒ…æ„Ÿ
     */
    public void predictSentiment(String text) {
        SentimentPrediction prediction = trainer.predict(text);
        System.out.println("\n=== æƒ…æ„Ÿé¢„æµ‹ ===");
        System.out.println("æ–‡æœ¬: " + text);
        System.out.println("é¢„æµ‹ç»“æœ: " + prediction);
        
        // æ˜¾ç¤ºè¯¦ç»†æ¦‚ç‡
        double[] probs = prediction.getProbabilities();
        System.out.printf("è´Ÿé¢æ¦‚ç‡: %.2f%%, æ­£é¢æ¦‚ç‡: %.2f%%%n", 
            probs[0] * 100, probs[1] * 100);
    }
    
    /**
     * æ‰¹é‡é¢„æµ‹
     */
    public void predictBatch(List<String> texts) {
        System.out.println("\n=== æ‰¹é‡æƒ…æ„Ÿé¢„æµ‹ ===");
        List<SentimentPrediction> predictions = trainer.predictBatch(texts);
        
        for (int i = 0; i < texts.size(); i++) {
            System.out.printf("æ–‡æœ¬ %d: %s%n", i + 1, texts.get(i));
            System.out.println("  é¢„æµ‹ç»“æœ: " + predictions.get(i));
            System.out.println();
        }
    }
    
    /**
     * è¯„ä¼°æ¨¡å‹æ€§èƒ½
     */
    public void evaluate() {
        // é‡æ–°é¢„å¤„ç†æ•°æ®é›†
        ProcessedDataset processedDataset = preprocessor.preprocessDataset(dataset);
        DatasetSplit split = preprocessor.splitDataset(processedDataset, 0.8);
        
        EvaluationResult trainResult = model.evaluate(
            split.getTrainDataset().getFeatures(),
            split.getTrainDataset().getLabels()
        );
        
        EvaluationResult testResult = model.evaluate(
            split.getTestDataset().getFeatures(),
            split.getTestDataset().getLabels()
        );
        
        System.out.println("\n=== æ¨¡å‹è¯„ä¼° ===");
        System.out.println("è®­ç»ƒé›†: " + trainResult);
        System.out.println("æµ‹è¯•é›†: " + testResult);
    }
}

/**
 * æƒ…æ„Ÿåˆ†æç³»ç»Ÿæ¼”ç¤º
 */
public class SentimentAnalysisDemo {
    public static void main(String[] args) {
        System.out.println("=== æƒ…æ„Ÿåˆ†æç³»ç»Ÿæ¼”ç¤º ===");
        
        // åˆ›å»ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ
        SentimentAnalysisSystem system = new SentimentAnalysisSystem();
        
        // è®­ç»ƒæ¨¡å‹
        system.train();
        
        // è¯„ä¼°æ¨¡å‹
        system.evaluate();
        
        // é¢„æµ‹ç¤ºä¾‹
        System.out.println("\n=== é¢„æµ‹ç¤ºä¾‹ ===");
        system.predictSentiment("è¿™éƒ¨ç”µå½±çœŸçš„å¾ˆæ£’ï¼Œæˆ‘éå¸¸å–œæ¬¢ï¼");
        system.predictSentiment("è¿™éƒ¨ç”µå½±å¤ªç³Ÿç³•äº†ï¼Œå®Œå…¨ä¸æ¨èã€‚");
        system.predictSentiment("ä¸€èˆ¬èˆ¬å§ï¼Œæ²¡æœ‰ä»€ä¹ˆç‰¹åˆ«çš„æ„Ÿè§‰ã€‚");
        
        // æ‰¹é‡é¢„æµ‹ç¤ºä¾‹
        List<String> testTexts = Arrays.asList(
            "æ¼”å‘˜è¡¨æ¼”å¾ˆå‡ºè‰²ï¼Œå‰§æƒ…ä¹Ÿå¾ˆå¸å¼•äººã€‚",
            "ç‰¹æ•ˆä¸é”™ï¼Œä½†æ˜¯å‰§æƒ…æœ‰äº›æ‹–æ²“ã€‚",
            "è¿™æ˜¯æˆ‘çœ‹è¿‡æœ€å·®çš„ç”µå½±ä¹‹ä¸€ã€‚",
            "å¼ºçƒˆæ¨èï¼ç»å¯¹å€¼å¾—ä¸€çœ‹ã€‚"
        );
        
        system.predictBatch(testTexts);
    }
}
```

## 9.4.6 æ¨¡å‹æ€§èƒ½ä¼˜åŒ–

åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬è¿˜éœ€è¦è€ƒè™‘æ¨¡å‹çš„æ€§èƒ½ä¼˜åŒ–ï¼š

```java
/**
 * æ¨¡å‹ä¼˜åŒ–å·¥å…·ç±»
 */
public class ModelOptimizer {
    
    /**
     * å­¦ä¹ ç‡è°ƒåº¦
     */
    public static class LearningRateScheduler {
        private double initialLearningRate;
        private String scheduleType;
        
        public LearningRateScheduler(double initialLearningRate, String scheduleType) {
            this.initialLearningRate = initialLearningRate;
            this.scheduleType = scheduleType;
        }
        
        /**
         * æ ¹æ®epochè®¡ç®—å½“å‰å­¦ä¹ ç‡
         */
        public double getLearningRate(int epoch) {
            switch (scheduleType) {
                case "step":
                    return stepDecay(epoch);
                case "exponential":
                    return exponentialDecay(epoch);
                case "cosine":
                    return cosineDecay(epoch);
                default:
                    return initialLearningRate;
            }
        }
        
        /**
         * é˜¶æ¢¯å¼è¡°å‡
         */
        private double stepDecay(int epoch) {
            int dropEvery = 30;
            double dropRate = 0.5;
            int timesDropped = epoch / dropEvery;
            return initialLearningRate * Math.pow(dropRate, timesDropped);
        }
        
        /**
         * æŒ‡æ•°è¡°å‡
         */
        private double exponentialDecay(int epoch) {
            double decayRate = 0.05;
            return initialLearningRate * Math.exp(-decayRate * epoch);
        }
        
        /**
         * ä½™å¼¦è¡°å‡
         */
        private double cosineDecay(int epoch) {
            int maxEpochs = 100;
            return initialLearningRate * (1 + Math.cos(Math.PI * epoch / maxEpochs)) / 2;
        }
    }
    
    /**
     * æ—©åœæœºåˆ¶
     */
    public static class EarlyStopping {
        private int patience;
        private double minDelta;
        private int patienceCounter;
        private double bestLoss;
        private boolean stopped;
        
        public EarlyStopping(int patience, double minDelta) {
            this.patience = patience;
            this.minDelta = minDelta;
            this.patienceCounter = 0;
            this.bestLoss = Double.MAX_VALUE;
            this.stopped = false;
        }
        
        /**
         * æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢è®­ç»ƒ
         */
        public boolean shouldStop(double currentLoss) {
            if (stopped) {
                return true;
            }
            
            if (currentLoss < bestLoss - minDelta) {
                bestLoss = currentLoss;
                patienceCounter = 0;
            } else {
                patienceCounter++;
                if (patienceCounter >= patience) {
                    stopped = true;
                    System.out.println("è§¦å‘æ—©åœæœºåˆ¶ï¼Œåœæ­¢è®­ç»ƒ");
                }
            }
            
            return stopped;
        }
        
        public boolean isStopped() {
            return stopped;
        }
    }
    
    /**
     * æ¨¡å‹æ£€æŸ¥ç‚¹
     */
    public static class ModelCheckpoint {
        private String savePath;
        private double bestScore;
        private boolean maximize;
        
        public ModelCheckpoint(String savePath, boolean maximize) {
            this.savePath = savePath;
            this.bestScore = maximize ? Double.MIN_VALUE : Double.MAX_VALUE;
            this.maximize = maximize;
        }
        
        /**
         * æ£€æŸ¥æ˜¯å¦åº”è¯¥ä¿å­˜æ¨¡å‹
         */
        public boolean shouldSave(double currentScore) {
            boolean shouldSave = maximize ? 
                (currentScore > bestScore) : (currentScore < bestScore);
            
            if (shouldSave) {
                bestScore = currentScore;
                System.out.println("ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹ï¼Œæœ€ä½³å¾—åˆ†: " + bestScore);
            }
            
            return shouldSave;
        }
    }
}
```

## æœ¬èŠ‚å°ç»“

### æ ¸å¿ƒçŸ¥è¯†å›é¡¾

æœ¬èŠ‚æ•´åˆäº†å‰é¢æ‰€å­¦çš„æ‰€æœ‰æŠ€æœ¯,æ„å»ºäº†ä¸€ä¸ªå®Œæ•´çš„æƒ…æ„Ÿåˆ†æç³»ç»Ÿ:

```mermaid
graph LR
    A[9.1 æ–‡æœ¬é¢„å¤„ç†] --> E[å®Œæ•´ç³»ç»Ÿ]
    B[9.2 è¯åµŒå…¥] --> E
    C[9.3 LSTM] --> E
    D[9.4 æ•´åˆåº”ç”¨] --> E
    
    E --> F[å®é™…åº”ç”¨]
```

**å®Œæ•´æµç¨‹:**

| æ­¥éª¤ | æŠ€æœ¯ | ç±»æ¯” | ä½œç”¨ |
|------|------|------|------|
| **æ•°æ®å‡†å¤‡** | æ•°æ®é›†æ„å»º | å‡†å¤‡ç»ƒä¹ é¢˜ | æ”¶é›†è®­ç»ƒæ ·æœ¬ |
| **é¢„å¤„ç†** | æ¸…æ´—+åˆ†è¯+ç¼–ç  | æ´—èœ+åˆ‡èœ+æ‘†ç›˜ | è½¬ä¸ºæ ‡å‡†æ ¼å¼ |
| **è¯åµŒå…¥** | è¯å‘é‡ | GPSåæ ‡ | æ•æ‰è¯è¯­ä¹‰ |
| **åºåˆ—å»ºæ¨¡** | LSTM | ç†è§£å¥å­ | æ•æ‰ä¸Šä¸‹æ–‡ |
| **åˆ†ç±»** | Softmax | è¯„å§”æ‰“åˆ† | è¾“å‡ºåˆ¤æ–­ |
| **è®­ç»ƒ** | åå‘ä¼ æ’­ | åšç»ƒä¹ æ”¹é”™ | ä¼˜åŒ–å‚æ•° |
| **è¯„ä¼°** | å‡†ç¡®ç‡ | è€ƒè¯•æ‰“åˆ† | éªŒè¯æ•ˆæœ |

**å…³é”®è¦ç‚¹:**

1. **æ•°æ®è´¨é‡ç¬¬ä¸€**:åƒåœ¾è¿›,åƒåœ¾å‡º
   - æ•°æ®è¦å¹²å‡€,æ ‡æ³¨è¦å‡†ç¡®
   - è®­ç»ƒé›†è¦è¶³å¤Ÿå¤§ä¸”å¹³è¡¡

2. **æ¨¡å‹é€‰æ‹©åˆç†**:
   - çŸ­æ–‡æœ¬(<10è¯):ç®€å•æ¨¡å‹(RNN)
   - é•¿æ–‡æœ¬(>50è¯):å¤æ‚æ¨¡å‹(LSTM/GRU)
   - è¶…é•¿æ–‡æœ¬:è€ƒè™‘Transformer

3. **è¶…å‚æ•°è°ƒä¼˜**:
   - embedding_dim: 50-300
   - hidden_size: 64-512
   - learning_rate: 0.001-0.01
   - max_length: æ ¹æ®æ•°æ®åˆ†å¸ƒå†³å®š

4. **è¯„ä¼°è¦å…¨é¢**:
   - ä¸åªçœ‹å‡†ç¡®ç‡
   - è¿˜è¦çœ‹ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°
   - åˆ†ææ··æ·†çŸ©é˜µ,æ‰¾å‡ºé—®é¢˜

**å®è·µå»ºè®®:**

- **ä»ç®€å•å¼€å§‹**:å…ˆç”¨å°æ•°æ®é›†å¿«é€ŸéªŒè¯
- **é€æ­¥ä¼˜åŒ–**:baseline â†’ è°ƒå‚ â†’ æ”¹è¿›æ¨¡å‹
- **å…³æ³¨ç»†èŠ‚**:æ•°æ®é¢„å¤„ç†å¾€å¾€æ¯”æ¨¡å‹æ›´é‡è¦
- **æŒç»­è¿­ä»£**:æ”¶é›†badcase,é’ˆå¯¹æ€§æ”¹è¿›

### æ€è€ƒä¸ç»ƒä¹ 

1. **æ€è€ƒé¢˜**:ä¸ºä»€ä¹ˆæƒ…æ„Ÿåˆ†æä¸­,"ä¸å¥½çœ‹"å’Œ"ä¸æ˜¯ä¸å¥½çœ‹"çš„å¤„ç†ç»“æœåº”è¯¥ä¸åŒ?LSTMå¦‚ä½•æ•æ‰è¿™ç§å·®å¼‚?

2. **å®è·µé¢˜**:ä½¿ç”¨TinyAIå®ç°ä¸€ä¸ªä¸‰åˆ†ç±»çš„æƒ…æ„Ÿåˆ†æç³»ç»Ÿ(æ­£é¢/ä¸­æ€§/è´Ÿé¢),è§‚å¯Ÿä¸äºŒåˆ†ç±»çš„å·®å¼‚ã€‚

3. **æ‰©å±•é¢˜**:ç ”ç©¶å¦‚ä½•å¤„ç†å¤šè¯­è¨€æ··åˆçš„è¯„è®º(å¦‚ä¸­è‹±æ–‡æ··åˆ),éœ€è¦åšå“ªäº›ç‰¹æ®Šå¤„ç†?

## ä¸‹ä¸€æ­¥å­¦ä¹ 

åœ¨ä¸‹ä¸€èŠ‚ä¸­,æˆ‘ä»¬å°†å­¦ä¹ **åºåˆ—åˆ°åºåˆ—(Seq2Seq)æ¨¡å‹**,äº†è§£å¦‚ä½•å®ç°æœºå™¨ç¿»è¯‘ç­‰æ›´å¤æ‚çš„ä»»åŠ¡ã€‚

å¦‚æœè¯´æœ¬èŠ‚æ˜¯"åˆ†ç±»ä»»åŠ¡"(è¾“å…¥å¥å­â†’è¾“å‡ºæ ‡ç­¾),é‚£ä¹ˆä¸‹ä¸€èŠ‚å°±æ˜¯"ç”Ÿæˆä»»åŠ¡"(è¾“å…¥å¥å­â†’è¾“å‡ºå¥å­),éš¾åº¦å’Œåº”ç”¨åœºæ™¯éƒ½æ›´ä¸Šä¸€å±‚æ¥¼!

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå®Œæ•´çš„æƒ…æ„Ÿåˆ†æç³»ç»Ÿï¼Œæ¶µç›–äº†ä»¥ä¸‹å…³é”®å†…å®¹ï¼š

1. **æ•°æ®é›†æ„å»º**ï¼šåˆ›å»ºäº†é€‚åˆæƒ…æ„Ÿåˆ†æä»»åŠ¡çš„ç¤ºä¾‹æ•°æ®é›†
2. **æ•°æ®é¢„å¤„ç†**ï¼šå®ç°äº†ä»åŸå§‹æ–‡æœ¬åˆ°æ¨¡å‹è¾“å…¥çš„å®Œæ•´é¢„å¤„ç†æµæ°´çº¿
3. **æ¨¡å‹å®ç°**ï¼šåŸºäºLSTMæ„å»ºäº†æƒ…æ„Ÿåˆ†ææ¨¡å‹
4. **è®­ç»ƒæµç¨‹**ï¼šå®ç°äº†å®Œæ•´çš„è®­ç»ƒã€éªŒè¯å’Œè¯„ä¼°æµç¨‹
5. **é¢„æµ‹åŠŸèƒ½**ï¼šæä¾›äº†å•ä¸ªå’Œæ‰¹é‡æ–‡æœ¬çš„æƒ…æ„Ÿé¢„æµ‹åŠŸèƒ½
6. **æ€§èƒ½ä¼˜åŒ–**ï¼šä»‹ç»äº†å­¦ä¹ ç‡è°ƒåº¦ã€æ—©åœæœºåˆ¶ç­‰ä¼˜åŒ–æŠ€æœ¯

é€šè¿‡è¿™ä¸ªå®æˆ˜é¡¹ç›®ï¼Œæˆ‘ä»¬ä¸ä»…å·©å›ºäº†å‰é¢å­¦ä¹ çš„ç†è®ºçŸ¥è¯†ï¼Œè¿˜è·å¾—äº†å®é™…çš„é¡¹ç›®å¼€å‘ç»éªŒã€‚æƒ…æ„Ÿåˆ†æç³»ç»Ÿæ˜¯NLPé¢†åŸŸçš„é‡è¦åº”ç”¨ä¹‹ä¸€ï¼ŒæŒæ¡å…¶å®ç°æ–¹æ³•å¯¹åç»­å­¦ä¹ æ›´å¤æ‚çš„NLPä»»åŠ¡å…·æœ‰é‡è¦æ„ä¹‰ã€‚

## ä¸‹ä¸€æ­¥è®¡åˆ’

åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ åºåˆ—åˆ°åºåˆ—æ¨¡å‹ï¼Œè¿™æ˜¯æœºå™¨ç¿»è¯‘ç­‰ä»»åŠ¡çš„æ ¸å¿ƒæŠ€æœ¯ã€‚