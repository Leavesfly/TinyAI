# TinyAI VLA 故障排查手册

> 快速诊断和解决VLA模块常见问题的实用指南

## 📋 目录

- [1. 训练问题](#1-训练问题)
- [2. 推理问题](#2-推理问题)
- [3. 性能问题](#3-性能问题)
- [4. 内存问题](#4-内存问题)
- [5. 数据问题](#5-数据问题)
- [6. 环境问题](#6-环境问题)
- [7. 部署问题](#7-部署问题)
- [8. 日志分析](#8-日志分析)

---

## 1. 训练问题

### 问题1.1: 损失不下降 / NaN

**症状**:
```
Training Episode 10 - Loss: 5.234
Training Episode 20 - Loss: 5.189
Training Episode 30 - Loss: 5.201
Training Episode 40 - Loss: NaN
```

**可能原因及解决方案**:

#### 原因A: 学习率过大

**诊断**:
```java
// 检查学习率
System.out.println("Current Learning Rate: " + learner.getLearningRate());
```

**解决方案**:
```java
// 降低学习率
learner.setLearningRate(0.0001);  // 原来是0.001

// 或使用梯度裁剪
double maxGradNorm = 1.0;
agent.clipGradients(maxGradNorm);
```

---

#### 原因B: 数值不稳定

**诊断**:
```java
// 检查输入数据范围
public void checkDataRange(NdArray data) {
    double min = data.min();
    double max = data.max();
    System.out.printf("Data range: [%.2f, %.2f]%n", min, max);
    
    // 检查是否有NaN或Inf
    if (data.hasNaN()) {
        System.err.println("WARNING: Data contains NaN!");
    }
    if (data.hasInf()) {
        System.err.println("WARNING: Data contains Inf!");
    }
}
```

**解决方案**:
```java
// 添加数值稳定性处理
public NdArray softmax(NdArray logits) {
    // 减去最大值，防止exp溢出
    NdArray maxLogits = logits.max(keepdims=true);
    NdArray expLogits = logits.sub(maxLogits).exp();
    
    // 添加小常数，防止除零
    NdArray sumExp = expLogits.sum(keepdims=true).add(NdArray.of(1e-8));
    
    return expLogits.div(sumExp);
}
```

---

#### 原因C: 批归一化问题

**诊断**:
```java
// 检查是否正确设置训练/评估模式
System.out.println("Model mode: " + (agent.isTraining() ? "Training" : "Eval"));
```

**解决方案**:
```java
// 训练时
agent.train();  // 设置为训练模式

// 评估时
agent.eval();  // 设置为评估模式
```

---

### 问题1.2: 训练速度过慢

**症状**:
```
Episode 1 completed in 45 seconds
Episode 2 completed in 47 seconds
Average: ~46 seconds per episode
(Expected: ~5 seconds per episode)
```

**可能原因及解决方案**:

#### 原因A: 批次大小太小

**诊断**:
```java
System.out.println("Current batch size: " + config.getBatchSize());
```

**解决方案**:
```java
// 增大批次大小
config.setBatchSize(64);  // 原来是8

// 如果内存不足，使用梯度累积
int accumulationSteps = 8;
int microBatchSize = 8;
// 等效批次大小 = 8 * 8 = 64
```

---

#### 原因B: 数据加载瓶颈

**诊断**:
```java
long startTime = System.currentTimeMillis();
VLAState state = env.reset();
long endTime = System.currentTimeMillis();
System.out.println("Data loading time: " + (endTime - startTime) + "ms");
```

**解决方案**:
```java
// 使用数据预加载
ExecutorService dataLoader = Executors.newFixedThreadPool(2);

Future<VLAState> nextState = dataLoader.submit(() -> env.reset());

// 在训练的同时加载下一个数据
VLAState currentState = nextState.get();
nextState = dataLoader.submit(() -> env.reset());
```

---

#### 原因C: 冗余计算

**诊断**:
```java
// 使用性能分析
Profiler profiler = new Profiler();
profiler.start("forward_pass");
agent.forward(state);
profiler.stop("forward_pass");

profiler.start("backward_pass");
agent.backward(loss);
profiler.stop("backward_pass");

profiler.printStats();
```

**解决方案**:
```java
// 缓存不变的特征
private Map<String, NdArray> languageFeatureCache = new HashMap<>();

public NdArray encodeLanguage(String instruction) {
    if (languageFeatureCache.containsKey(instruction)) {
        return languageFeatureCache.get(instruction);
    }
    
    NdArray features = languageEncoder.encode(instruction);
    languageFeatureCache.put(instruction, features);
    return features;
}
```

---

### 问题1.3: 模型过拟合

**症状**:
```
Training Reward: 95.2  ✓
Validation Reward: 32.5  ✗
(训练集表现好，验证集表现差)
```

**可能原因及解决方案**:

#### 原因A: 训练数据不够多样化

**诊断**:
```java
// 检查环境随机性
public void checkEnvironmentDiversity() {
    Set<String> uniqueStates = new HashSet<>();
    
    for (int i = 0; i < 100; i++) {
        VLAState state = env.reset();
        uniqueStates.add(state.toString());
    }
    
    System.out.println("Unique states: " + uniqueStates.size() + " / 100");
    // 如果 < 50，说明多样性不足
}
```

**解决方案**:
```java
// 增加环境随机性
public VLAState reset() {
    // 随机化物体位置
    double[] objectPos = randomPosition();
    
    // 随机化物体属性
    double mass = random.nextDouble() * 0.5 + 0.5;  // [0.5, 1.0]
    double friction = random.nextDouble() * 0.5 + 0.3;  // [0.3, 0.8]
    
    // 随机化视觉场景
    int lightingVariant = random.nextInt(5);
    String background = backgrounds[random.nextInt(backgrounds.length)];
    
    return createState(objectPos, mass, friction, lightingVariant, background);
}
```

---

#### 原因B: 模型容量过大

**诊断**:
```java
// 统计模型参数量
public long countParameters(VLAAgent agent) {
    long totalParams = 0;
    for (Parameter param : agent.parameters()) {
        totalParams += param.size();
    }
    System.out.println("Total parameters: " + totalParams);
    return totalParams;
}
```

**解决方案**:
```java
// 减小模型规模
VLAAgent smallerAgent = new VLAAgent(
    512,  // hiddenDim (原来768)
    4,    // numHeads (原来8)
    4,    // numLayers (原来6)
    7     // actionDim
);

// 或添加正则化
config.setDropout(0.2);  // 添加Dropout
config.setWeightDecay(1e-4);  // 添加L2正则化
```

---

## 2. 推理问题

### 问题2.1: 推理结果不合理

**症状**:
```java
VLAAction action = agent.predict(state);
System.out.println("Action: " + action.getContinuousAction());
// 输出: [NaN, NaN, NaN, ...]
// 或: [1000.0, -500.0, 999.9, ...]  (异常大的值)
```

**可能原因及解决方案**:

#### 原因A: 模型未加载或损坏

**诊断**:
```java
// 检查模型是否正确加载
public boolean checkModelLoaded(VLAAgent agent) {
    try {
        VLAState dummyState = createDummyState();
        VLAAction action = agent.predict(dummyState);
        
        // 检查输出是否合理
        if (action == null || action.hasNaN()) {
            System.err.println("Model output is invalid!");
            return false;
        }
        
        System.out.println("✓ Model loaded successfully");
        return true;
    } catch (Exception e) {
        System.err.println("✗ Model loading failed: " + e.getMessage());
        return false;
    }
}
```

**解决方案**:
```java
// 重新加载模型
try {
    agent = VLAAgent.load("models/vla_model.pth");
    
    // 验证加载
    if (!checkModelLoaded(agent)) {
        throw new RuntimeException("Model verification failed!");
    }
} catch (IOException e) {
    System.err.println("Failed to load model: " + e.getMessage());
    // 回退到备份模型
    agent = VLAAgent.load("models/vla_model_backup.pth");
}
```

---

#### 原因B: 输入数据未归一化

**诊断**:
```java
// 检查输入数据范围
public void diagnoseInput(VLAState state) {
    NdArray image = state.getVisionInput().getRgbImage();
    System.out.printf("Image range: [%.2f, %.2f]%n", 
        image.min(), image.max());
    // 应该在[0, 1]或[-1, 1]范围内
    
    NdArray proprio = state.getProprioceptionInput().getJointPositions();
    System.out.printf("Proprio range: [%.2f, %.2f]%n",
        proprio.min(), proprio.max());
}
```

**解决方案**:
```java
// 确保输入归一化
public VLAState preprocessState(VLAState state) {
    // 归一化图像到[0, 1]
    NdArray image = state.getVisionInput().getRgbImage();
    image = image.div(NdArray.of(255.0));
    state.getVisionInput().setRgbImage(image);
    
    // 归一化关节角度到[-1, 1]
    NdArray joints = state.getProprioceptionInput().getJointPositions();
    joints = normalizeJoints(joints);
    state.getProprioceptionInput().setJointPositions(joints);
    
    return state;
}
```

---

### 问题2.2: 推理延迟过高

**症状**:
```
Inference time: 250ms per prediction
(Expected: <50ms)
```

**可能原因及解决方案**:

#### 原因A: 未使用批处理

**诊断**:
```java
// 测量单个vs批量推理时间
long start = System.nanoTime();
for (int i = 0; i < 32; i++) {
    agent.predict(states.get(i));
}
long singleTime = System.nanoTime() - start;

start = System.nanoTime();
agent.batchPredict(states);
long batchTime = System.nanoTime() - start;

System.out.printf("Single: %dms, Batch: %dms, Speedup: %.1fx%n",
    singleTime / 1_000_000, batchTime / 1_000_000,
    (double) singleTime / batchTime);
```

**解决方案**:
```java
// 使用批处理推理
List<VLAState> stateBatch = new ArrayList<>();

// 收集批次
for (RobotEnvironment env : environments) {
    stateBatch.add(env.getCurrentState());
}

// 批量推理
List<VLAAction> actions = agent.batchPredict(stateBatch);

// 分发动作
for (int i = 0; i < environments.size(); i++) {
    environments.get(i).step(actions.get(i));
}
```

---

#### 原因B: 重复编码

**诊断**:
```java
// 分析推理时间分布
Profiler profiler = new Profiler();

profiler.start("vision_encoding");
NdArray visionFeatures = visionEncoder.encode(visionInput);
profiler.stop("vision_encoding");

profiler.start("language_encoding");
NdArray languageFeatures = languageEncoder.encode(languageInput);
profiler.stop("language_encoding");

profiler.start("action_decoding");
VLAAction action = actionDecoder.decode(fusedFeatures);
profiler.stop("action_decoding");

profiler.printStats();
// 如果language_encoding占用>30%时间，考虑缓存
```

**解决方案**:
```java
// 缓存语言特征（指令通常不变）
private NdArray cachedLanguageFeatures = null;
private String cachedInstruction = null;

public VLAAction predict(VLAState state) {
    String instruction = state.getLanguageInput().getInstruction();
    
    // 如果指令未变，复用缓存
    if (instruction.equals(cachedInstruction)) {
        languageFeatures = cachedLanguageFeatures;
    } else {
        languageFeatures = languageEncoder.encode(instruction);
        cachedLanguageFeatures = languageFeatures;
        cachedInstruction = instruction;
    }
    
    // ... 后续处理
}
```

---

## 3. 性能问题

### 问题3.1: GPU内存溢出

**症状**:
```
OutOfMemoryError: Java heap space
或
CUDA out of memory
```

**可能原因及解决方案**:

#### 原因A: 批次大小过大

**诊断**:
```java
// 测试不同批次大小的内存使用
Runtime runtime = Runtime.getRuntime();

for (int batchSize : new int[]{8, 16, 32, 64, 128}) {
    runtime.gc();
    long before = runtime.totalMemory() - runtime.freeMemory();
    
    try {
        List<VLAState> batch = createBatch(batchSize);
        agent.batchPredict(batch);
        
        long after = runtime.totalMemory() - runtime.freeMemory();
        long used = (after - before) / 1024 / 1024;  // MB
        
        System.out.printf("Batch size %d: %d MB%n", batchSize, used);
    } catch (OutOfMemoryError e) {
        System.out.printf("Batch size %d: OOM!%n", batchSize);
        break;
    }
}
```

**解决方案**:
```java
// 减小批次大小
config.setBatchSize(16);  // 原来是64

// 或使用梯度检查点（训练时）
agent.enableGradientCheckpointing(true);
```

---

#### 原因B: 计算图未释放

**诊断**:
```java
// 检查是否有内存泄漏
for (int i = 0; i < 100; i++) {
    agent.predict(state);
    
    if (i % 10 == 0) {
        Runtime runtime = Runtime.getRuntime();
        long used = (runtime.totalMemory() - runtime.freeMemory()) / 1024 / 1024;
        System.out.printf("Iteration %d: %d MB%n", i, used);
        // 如果内存持续增长，说明有泄漏
    }
}
```

**解决方案**:
```java
// 推理时不构建计算图
agent.eval();  // 设置为评估模式

// 或显式释放
public VLAAction predict(VLAState state) {
    try {
        return agent.forward(state);
    } finally {
        // 释放中间变量
        agent.clearIntermediateVariables();
    }
}
```

---

### 问题3.2: CPU使用率低

**症状**:
```
CPU使用率: 15% (8核心平均)
训练速度慢，但CPU和GPU都没有满载
```

**可能原因及解决方案**:

#### 原因A: 数据加载瓶颈

**诊断**:
```java
// 测量数据加载时间
long totalDataTime = 0;
long totalTrainTime = 0;

for (int i = 0; i < 100; i++) {
    long start = System.nanoTime();
    VLAState state = env.reset();
    totalDataTime += System.nanoTime() - start;
    
    start = System.nanoTime();
    learner.trainEpisode(agent, env);
    totalTrainTime += System.nanoTime() - start;
}

System.out.printf("Data loading: %.1f%%, Training: %.1f%%%n",
    totalDataTime * 100.0 / (totalDataTime + totalTrainTime),
    totalTrainTime * 100.0 / (totalDataTime + totalTrainTime));
// 如果数据加载>30%，需要优化
```

**解决方案**:
```java
// 使用多线程数据加载
ExecutorService dataLoader = Executors.newFixedThreadPool(4);

List<Future<VLAState>> futures = new ArrayList<>();
for (int i = 0; i < batchSize; i++) {
    futures.add(dataLoader.submit(() -> env.reset()));
}

// 收集结果
List<VLAState> batch = futures.stream()
    .map(f -> {
        try {
            return f.get();
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    })
    .collect(Collectors.toList());
```

---

## 4. 内存问题

### 问题4.1: 内存泄漏

**症状**:
```
训练开始: 2GB
训练1小时: 6GB
训练2小时: 10GB
训练3小时: 14GB -> OOM
```

**诊断步骤**:

```java
// 1. 启用内存监控
public class MemoryMonitor {
    private static final Runtime runtime = Runtime.getRuntime();
    
    public static void logMemory(String tag) {
        long used = (runtime.totalMemory() - runtime.freeMemory()) / 1024 / 1024;
        long max = runtime.maxMemory() / 1024 / 1024;
        System.out.printf("[%s] Memory: %d / %d MB (%.1f%%)%n",
            tag, used, max, used * 100.0 / max);
    }
}

// 2. 在关键位置监控
MemoryMonitor.logMemory("Before episode");
learner.trainEpisode(agent, env);
MemoryMonitor.logMemory("After episode");

runtime.gc();
MemoryMonitor.logMemory("After GC");
```

**常见泄漏点**:

```java
// ✗ 泄漏点1: 缓存无限增长
private Map<String, NdArray> cache = new HashMap<>();  // 从不清理

// ✓ 解决方案: 使用LRU缓存
private LinkedHashMap<String, NdArray> cache = new LinkedHashMap<>(100, 0.75f, true) {
    @Override
    protected boolean removeEldestEntry(Map.Entry eldest) {
        return size() > 100;  // 最多保留100项
    }
};

// ✗ 泄漏点2: 监听器未移除
env.addListener(listener);  // 从不removeListener

// ✓ 解决方案: 使用try-finally
Listener listener = new MyListener();
try {
    env.addListener(listener);
    // 训练逻辑
} finally {
    env.removeListener(listener);
}

// ✗ 泄漏点3: 计算图未释放
Variable result = agent.forward(input);  // 保留了整个计算图

// ✓ 解决方案: 及时释放
Variable result = agent.forward(input);
try {
    // 使用result
} finally {
    result.clearGrad();
    result.unchain();  // 切断计算图
}
```

---

## 5. 数据问题

### 问题5.1: 数据分布不平衡

**症状**:
```
成功样本: 5%
失败样本: 95%
模型学会了总是预测失败
```

**诊断**:
```java
// 统计数据分布
public void analyzeDataDistribution(List<EpisodeData> episodes) {
    int successCount = 0;
    int failCount = 0;
    
    for (EpisodeData episode : episodes) {
        if (episode.isSuccess()) {
            successCount++;
        } else {
            failCount++;
        }
    }
    
    double successRate = successCount * 100.0 / episodes.size();
    System.out.printf("Success: %d (%.1f%%), Fail: %d (%.1f%%)%n",
        successCount, successRate, failCount, 100 - successRate);
    
    if (successRate < 20 || successRate > 80) {
        System.err.println("WARNING: Data is imbalanced!");
    }
}
```

**解决方案**:

```java
// 方案1: 过采样少数类
public List<EpisodeData> balanceData(List<EpisodeData> episodes) {
    List<EpisodeData> successEpisodes = episodes.stream()
        .filter(EpisodeData::isSuccess)
        .collect(Collectors.toList());
    
    List<EpisodeData> failEpisodes = episodes.stream()
        .filter(e -> !e.isSuccess())
        .collect(Collectors.toList());
    
    // 重复采样成功样本
    int targetCount = failEpisodes.size();
    List<EpisodeData> balanced = new ArrayList<>(failEpisodes);
    
    Random random = new Random();
    while (balanced.size() < targetCount * 2) {
        balanced.add(successEpisodes.get(random.nextInt(successEpisodes.size())));
    }
    
    Collections.shuffle(balanced);
    return balanced;
}

// 方案2: 加权损失
public double computeWeightedLoss(VLAAction predicted, VLAAction actual, boolean isSuccess) {
    double loss = computeLoss(predicted, actual);
    
    // 成功样本权重更高
    double weight = isSuccess ? 2.0 : 1.0;
    
    return loss * weight;
}
```

---

## 6. 环境问题

### 问题6.1: 环境初始化失败

**症状**:
```
Exception in thread "main" NullPointerException
at SimpleRobotEnv.reset(SimpleRobotEnv.java:45)
```

**诊断和解决**:

```java
// 添加详细的错误检查
public VLAState reset() {
    try {
        // 检查配置
        if (taskConfig == null) {
            throw new IllegalStateException("TaskConfig not set!");
        }
        
        // 检查工作空间
        if (workspace == null || workspace.isEmpty()) {
            throw new IllegalStateException("Workspace not initialized!");
        }
        
        // 初始化状态
        VLAState state = initializeState();
        
        // 验证状态
        if (!validateState(state)) {
            throw new IllegalStateException("Invalid initial state!");
        }
        
        return state;
        
    } catch (Exception e) {
        System.err.println("Environment reset failed:");
        e.printStackTrace();
        
        // 尝试恢复
        return createDefaultState();
    }
}

// 状态验证
private boolean validateState(VLAState state) {
    if (state == null) return false;
    
    if (state.getVisionInput() == null) {
        System.err.println("Vision input is null!");
        return false;
    }
    
    if (state.getLanguageInput() == null) {
        System.err.println("Language input is null!");
        return false;
    }
    
    return true;
}
```

---

## 7. 部署问题

### 问题7.1: 模型加载失败

**症状**:
```
Failed to load model: File not found
或
Model version mismatch
```

**解决方案**:

```java
public VLAAgent loadModelSafely(String modelPath) {
    // 1. 检查文件是否存在
    File modelFile = new File(modelPath);
    if (!modelFile.exists()) {
        System.err.println("Model file not found: " + modelPath);
        
        // 尝试从备份位置加载
        String backupPath = modelPath.replace(".pth", "_backup.pth");
        if (new File(backupPath).exists()) {
            System.out.println("Loading from backup: " + backupPath);
            return loadModelSafely(backupPath);
        }
        
        throw new FileNotFoundException("No model file found");
    }
    
    // 2. 检查模型版本
    ModelMetadata metadata = readMetadata(modelPath);
    if (!isCompatible(metadata)) {
        System.err.println("Model version incompatible!");
        System.err.println("Model version: " + metadata.getVersion());
        System.err.println("Required version: " + CURRENT_VERSION);
        
        throw new IllegalStateException("Version mismatch");
    }
    
    // 3. 加载模型
    try {
        VLAAgent agent = VLAAgent.load(modelPath);
        
        // 4. 验证模型
        if (!verifyModel(agent)) {
            throw new IllegalStateException("Model verification failed");
        }
        
        System.out.println("✓ Model loaded successfully");
        return agent;
        
    } catch (Exception e) {
        System.err.println("Failed to load model: " + e.getMessage());
        throw new RuntimeException(e);
    }
}
```

---

## 8. 日志分析

### 8.1 日志级别设置

```java
// 推荐的日志配置
public class VLALogger {
    private static final Logger logger = Logger.getLogger("VLA");
    
    static {
        // 开发环境：DEBUG
        // 生产环境：INFO
        logger.setLevel(Level.INFO);
        
        // 控制台输出
        ConsoleHandler console = new ConsoleHandler();
        console.setLevel(Level.INFO);
        logger.addHandler(console);
        
        // 文件输出
        try {
            FileHandler file = new FileHandler("vla_%g.log", 10_000_000, 10);
            file.setLevel(Level.ALL);
            logger.addHandler(file);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
    
    public static void logTrainingStep(int episode, double reward, double loss) {
        logger.info(String.format("Episode %d - Reward: %.2f, Loss: %.4f",
            episode, reward, loss));
    }
    
    public static void logError(String message, Exception e) {
        logger.log(Level.SEVERE, message, e);
    }
}
```

---

### 8.2 关键指标监控

```java
public class MetricsCollector {
    private Map<String, List<Double>> metrics = new HashMap<>();
    
    public void record(String name, double value) {
        metrics.computeIfAbsent(name, k -> new ArrayList<>()).add(value);
    }
    
    public void printSummary() {
        System.out.println("=== Metrics Summary ===");
        
        for (Map.Entry<String, List<Double>> entry : metrics.entrySet()) {
            String name = entry.getKey();
            List<Double> values = entry.getValue();
            
            double mean = values.stream().mapToDouble(Double::doubleValue).average().orElse(0.0);
            double std = calculateStd(values);
            double min = values.stream().mapToDouble(Double::doubleValue).min().orElse(0.0);
            double max = values.stream().mapToDouble(Double::doubleValue).max().orElse(0.0);
            
            System.out.printf("%s: μ=%.2f, σ=%.2f, min=%.2f, max=%.2f%n",
                name, mean, std, min, max);
        }
    }
}
```

---

## 📞 获取帮助

如果本手册未能解决您的问题，请：

1. **查看技术文档**: [技术架构文档](技术架构文档.md)
2. **参考最佳实践**: [最佳实践指南](最佳实践指南.md)
3. **提交Issue**: https://github.com/TinyAI/issues
4. **社区讨论**: https://discuss.tinyai.io

---

**版本**: v1.0  
**更新时间**: 2025-10-18  
**维护者**: TinyAI VLA Team

*持续更新中，欢迎反馈！*
