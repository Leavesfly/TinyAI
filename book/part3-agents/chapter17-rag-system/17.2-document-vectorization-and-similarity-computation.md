# 17.2 文档向量化与相似度计算

> **设计思想**：掌握文档向量化和相似度计算技术，实现高效的文档检索和匹配

## 本节概述

文档向量化是RAG系统中的核心技术之一，它将文本、图像等非结构化数据转换为数值向量表示，使得计算机能够进行数学计算和相似度比较。相似度计算则是基于这些向量表示来衡量文档之间的相关性，从而实现高效的文档检索。

本节将深入探讨文档向量化的方法，包括传统的词袋模型、TF-IDF，以及现代的词嵌入和句子嵌入技术。同时，我们还将学习各种相似度计算方法，如余弦相似度、欧氏距离等，并通过实际代码实现来加深理解。

## 学习目标

完成本节学习后，你将：

- ✅ **掌握文档向量化方法**：理解词袋模型、TF-IDF、词嵌入和句子嵌入的原理和实现
- ✅ **实现向量化系统**：学会构建完整的文档向量化处理流程
- ✅ **掌握相似度计算技术**：理解各种相似度计算方法的原理和应用场景
- ✅ **构建向量数据库**：学会设计和实现高效的向量存储和检索系统
- ✅ **优化向量化性能**：掌握向量化和相似度计算的性能优化技术

## 文档向量化方法

### 1. 词袋模型（Bag of Words, BoW）

词袋模型是最简单的文档向量化方法，它将文档表示为词汇表中各个词的出现频率。

```java
public class BagOfWordsVectorizer {
    private Set<String> vocabulary;
    private Map<String, Integer> wordToIndex;
    
    public BagOfWordsVectorizer() {
        this.vocabulary = new HashSet<>();
        this.wordToIndex = new HashMap<>();
    }
    
    public void buildVocabulary(List<String> documents) {
        // 构建词汇表
        for (String doc : documents) {
            String[] words = preprocessText(doc).split("\\s+");
            for (String word : words) {
                vocabulary.add(word.toLowerCase());
            }
        }
        
        // 创建词到索引的映射
        int index = 0;
        for (String word : vocabulary) {
            wordToIndex.put(word, index++);
        }
    }
    
    public double[] vectorize(String document) {
        String[] words = preprocessText(document).split("\\s+");
        double[] vector = new double[vocabulary.size()];
        
        // 统计词频
        Map<String, Integer> wordCount = new HashMap<>();
        for (String word : words) {
            String lowerWord = word.toLowerCase();
            wordCount.put(lowerWord, wordCount.getOrDefault(lowerWord, 0) + 1);
        }
        
        // 构建向量
        for (Map.Entry<String, Integer> entry : wordCount.entrySet()) {
            String word = entry.getKey();
            int count = entry.getValue();
            if (wordToIndex.containsKey(word)) {
                int idx = wordToIndex.get(word);
                vector[idx] = count;
            }
        }
        
        return vector;
    }
    
    private String preprocessText(String text) {
        // 文本预处理：移除标点符号，转换为小写
        return text.replaceAll("[^a-zA-Z0-9\\s]", "").toLowerCase().trim();
    }
    
    public int getVocabularySize() {
        return vocabulary.size();
    }
    
    public Set<String> getVocabulary() {
        return new HashSet<>(vocabulary);
    }
}
```

### 2. TF-IDF（Term Frequency-Inverse Document Frequency）

TF-IDF是一种统计方法，用于评估一个词对于一个文档集或语料库中某份文档的重要程度。

```java
public class TFIDFVectorizer {
    private List<String> documents;
    private Map<String, Integer> wordToIndex;
    private Map<String, Double> idfMap;
    private int vocabularySize;
    
    public TFIDFVectorizer() {
        this.documents = new ArrayList<>();
        this.wordToIndex = new HashMap<>();
        this.idfMap = new HashMap<>();
    }
    
    public void fit(List<String> documents) {
        this.documents = new ArrayList<>(documents);
        buildVocabulary(documents);
        calculateIDF(documents);
    }
    
    private void buildVocabulary(List<String> documents) {
        Set<String> vocabulary = new HashSet<>();
        
        // 收集所有词汇
        for (String doc : documents) {
            String[] words = preprocessText(doc).split("\\s+");
            for (String word : words) {
                vocabulary.add(word.toLowerCase());
            }
        }
        
        // 创建词到索引的映射
        int index = 0;
        for (String word : vocabulary) {
            wordToIndex.put(word, index++);
        }
        
        this.vocabularySize = vocabulary.size();
    }
    
    private void calculateIDF(List<String> documents) {
        int totalDocs = documents.size();
        
        // 计算每个词的IDF值
        for (String word : wordToIndex.keySet()) {
            int docFrequency = 0;
            
            // 统计包含该词的文档数量
            for (String doc : documents) {
                if (preprocessText(doc).toLowerCase().contains(word)) {
                    docFrequency++;
                }
            }
            
            // 计算IDF值
            double idf = Math.log((double) totalDocs / docFrequency);
            idfMap.put(word, idf);
        }
    }
    
    public double[] transform(String document) {
        String[] words = preprocessText(document).split("\\s+");
        double[] vector = new double[vocabularySize];
        
        // 计算词频
        Map<String, Integer> wordCount = new HashMap<>();
        for (String word : words) {
            String lowerWord = word.toLowerCase();
            wordCount.put(lowerWord, wordCount.getOrDefault(lowerWord, 0) + 1);
        }
        
        int totalWords = words.length;
        
        // 计算TF-IDF值
        for (Map.Entry<String, Integer> entry : wordCount.entrySet()) {
            String word = entry.getKey();
            int count = entry.getValue();
            
            if (wordToIndex.containsKey(word) && idfMap.containsKey(word)) {
                int idx = wordToIndex.get(word);
                double tf = (double) count / totalWords; // 词频
                double idf = idfMap.get(word); // 逆文档频率
                vector[idx] = tf * idf; // TF-IDF值
            }
        }
        
        return vector;
    }
    
    private String preprocessText(String text) {
        return text.replaceAll("[^a-zA-Z0-9\\s]", "").toLowerCase().trim();
    }
    
    public int getVocabularySize() {
        return vocabularySize;
    }
    
    public Map<String, Integer> getWordToIndex() {
        return new HashMap<>(wordToIndex);
    }
}
```

### 3. 词嵌入（Word Embeddings）

词嵌入是将词汇映射到连续向量空间的技术，能够捕捉词汇之间的语义关系。

```java
public class WordEmbeddingVectorizer {
    private Map<String, float[]> wordVectors;
    private int embeddingDimension;
    
    public WordEmbeddingVectorizer(int embeddingDimension) {
        this.wordVectors = new HashMap<>();
        this.embeddingDimension = embeddingDimension;
        initializeRandomVectors();
    }
    
    private void initializeRandomVectors() {
        // 初始化随机词向量（实际应用中应加载预训练的词向量）
        Random random = new Random(42); // 固定种子以确保可重现性
        String[] commonWords = {"the", "and", "or", "but", "in", "on", "at", "to", "for", "of", 
                               "with", "by", "is", "are", "was", "were", "be", "been", "have", 
                               "has", "had", "do", "does", "did", "will", "would", "could", 
                               "should", "may", "might", "must", "can", "this", "that", "these", 
                               "those", "i", "you", "he", "she", "it", "we", "they"};
        
        for (String word : commonWords) {
            float[] vector = new float[embeddingDimension];
            for (int i = 0; i < embeddingDimension; i++) {
                vector[i] = random.nextFloat() * 2 - 1; // [-1, 1]范围内的随机数
            }
            wordVectors.put(word.toLowerCase(), vector);
        }
    }
    
    public float[] vectorizeWord(String word) {
        String lowerWord = word.toLowerCase();
        if (wordVectors.containsKey(lowerWord)) {
            return Arrays.copyOf(wordVectors.get(lowerWord), embeddingDimension);
        } else {
            // 对于未登录词，返回零向量或随机向量
            return new float[embeddingDimension];
        }
    }
    
    public float[] vectorizeSentence(String sentence) {
        String[] words = preprocessText(sentence).split("\\s+");
        float[] sentenceVector = new float[embeddingDimension];
        
        if (words.length == 0) {
            return sentenceVector;
        }
        
        // 对所有词向量求平均
        for (String word : words) {
            float[] wordVector = vectorizeWord(word);
            for (int i = 0; i < embeddingDimension; i++) {
                sentenceVector[i] += wordVector[i];
            }
        }
        
        // 归一化
        for (int i = 0; i < embeddingDimension; i++) {
            sentenceVector[i] /= words.length;
        }
        
        return sentenceVector;
    }
    
    private String preprocessText(String text) {
        return text.replaceAll("[^a-zA-Z0-9\\s]", "").toLowerCase().trim();
    }
    
    public void addWordVector(String word, float[] vector) {
        if (vector.length != embeddingDimension) {
            throw new IllegalArgumentException("Vector dimension mismatch");
        }
        wordVectors.put(word.toLowerCase(), Arrays.copyOf(vector, embeddingDimension));
    }
    
    public int getEmbeddingDimension() {
        return embeddingDimension;
    }
    
    public Set<String> getVocabulary() {
        return new HashSet<>(wordVectors.keySet());
    }
}
```

### 4. 句子嵌入（Sentence Embeddings）

句子嵌入能够更好地捕捉整个句子的语义信息。

```java
public class SentenceEmbeddingVectorizer {
    private EmbeddingModel embeddingModel;
    private int embeddingDimension;
    
    public SentenceEmbeddingVectorizer(EmbeddingModel embeddingModel) {
        this.embeddingModel = embeddingModel;
        this.embeddingDimension = embeddingModel.getEmbeddingDimension();
    }
    
    public float[] vectorize(String sentence) {
        try {
            return embeddingModel.encode(sentence);
        } catch (Exception e) {
            // 如果编码失败，返回零向量
            return new float[embeddingDimension];
        }
    }
    
    public float[][] vectorizeBatch(List<String> sentences) {
        try {
            return embeddingModel.encode(sentences);
        } catch (Exception e) {
            // 如果批量编码失败，逐个编码
            float[][] vectors = new float[sentences.size()][embeddingDimension];
            for (int i = 0; i < sentences.size(); i++) {
                vectors[i] = vectorize(sentences.get(i));
            }
            return vectors;
        }
    }
    
    public double similarity(float[] vector1, float[] vector2) {
        return cosineSimilarity(vector1, vector2);
    }
    
    private double cosineSimilarity(float[] vector1, float[] vector2) {
        double dotProduct = 0.0;
        double norm1 = 0.0;
        double norm2 = 0.0;
        
        for (int i = 0; i < vector1.length; i++) {
            dotProduct += vector1[i] * vector2[i];
            norm1 += vector1[i] * vector1[i];
            norm2 += vector2[i] * vector2[i];
        }
        
        if (norm1 == 0 || norm2 == 0) {
            return 0.0;
        }
        
        return dotProduct / (Math.sqrt(norm1) * Math.sqrt(norm2));
    }
    
    public int getEmbeddingDimension() {
        return embeddingDimension;
    }
}

// 嵌入模型接口
interface EmbeddingModel {
    float[] encode(String text) throws Exception;
    float[][] encode(List<String> texts) throws Exception;
    int getEmbeddingDimension();
}

// 模拟嵌入模型实现
class MockEmbeddingModel implements EmbeddingModel {
    private int dimension;
    private Random random;
    
    public MockEmbeddingModel(int dimension) {
        this.dimension = dimension;
        this.random = new Random(42);
    }
    
    @Override
    public float[] encode(String text) {
        float[] vector = new float[dimension];
        for (int i = 0; i < dimension; i++) {
            vector[i] = random.nextFloat() * 2 - 1; // [-1, 1]范围内的随机数
        }
        return vector;
    }
    
    @Override
    public float[][] encode(List<String> texts) {
        float[][] vectors = new float[texts.size()][dimension];
        for (int i = 0; i < texts.size(); i++) {
            vectors[i] = encode(texts.get(i));
        }
        return vectors;
    }
    
    @Override
    public int getEmbeddingDimension() {
        return dimension;
    }
}
```

## 相似度计算方法

### 1. 余弦相似度（Cosine Similarity）

余弦相似度是衡量两个向量夹角的余弦值，常用于文本相似度计算。

```java
public class CosineSimilarityCalculator {
    
    public static double calculate(float[] vector1, float[] vector2) {
        if (vector1.length != vector2.length) {
            throw new IllegalArgumentException("Vector dimensions must match");
        }
        
        double dotProduct = 0.0;
        double norm1 = 0.0;
        double norm2 = 0.0;
        
        for (int i = 0; i < vector1.length; i++) {
            dotProduct += vector1[i] * vector2[i];
            norm1 += vector1[i] * vector1[i];
            norm2 += vector2[i] * vector2[i];
        }
        
        if (norm1 == 0 || norm2 == 0) {
            return 0.0; // 零向量与任何向量的相似度为0
        }
        
        return dotProduct / (Math.sqrt(norm1) * Math.sqrt(norm2));
    }
    
    public static double calculate(double[] vector1, double[] vector2) {
        if (vector1.length != vector2.length) {
            throw new IllegalArgumentException("Vector dimensions must match");
        }
        
        double dotProduct = 0.0;
        double norm1 = 0.0;
        double norm2 = 0.0;
        
        for (int i = 0; i < vector1.length; i++) {
            dotProduct += vector1[i] * vector2[i];
            norm1 += vector1[i] * vector1[i];
            norm2 += vector2[i] * vector2[i];
        }
        
        if (norm1 == 0 || norm2 == 0) {
            return 0.0;
        }
        
        return dotProduct / (Math.sqrt(norm1) * Math.sqrt(norm2));
    }
    
    // 批量计算相似度
    public static double[] calculateBatch(float[] queryVector, float[][] documentVectors) {
        double[] similarities = new double[documentVectors.length];
        for (int i = 0; i < documentVectors.length; i++) {
            similarities[i] = calculate(queryVector, documentVectors[i]);
        }
        return similarities;
    }
}
```

### 2. 欧氏距离（Euclidean Distance）

欧氏距离是衡量两个向量之间直线距离的方法。

```java
public class EuclideanDistanceCalculator {
    
    public static double calculate(float[] vector1, float[] vector2) {
        if (vector1.length != vector2.length) {
            throw new IllegalArgumentException("Vector dimensions must match");
        }
        
        double sumSquaredDiff = 0.0;
        for (int i = 0; i < vector1.length; i++) {
            double diff = vector1[i] - vector2[i];
            sumSquaredDiff += diff * diff;
        }
        
        return Math.sqrt(sumSquaredDiff);
    }
    
    public static double calculate(double[] vector1, double[] vector2) {
        if (vector1.length != vector2.length) {
            throw new IllegalArgumentException("Vector dimensions must match");
        }
        
        double sumSquaredDiff = 0.0;
        for (int i = 0; i < vector1.length; i++) {
            double diff = vector1[i] - vector2[i];
            sumSquaredDiff += diff * diff;
        }
        
        return Math.sqrt(sumSquaredDiff);
    }
    
    // 归一化的欧氏距离（转换为相似度）
    public static double calculateNormalized(float[] vector1, float[] vector2) {
        double euclideanDistance = calculate(vector1, vector2);
        // 转换为相似度：距离越小，相似度越高
        return 1.0 / (1.0 + euclideanDistance);
    }
}
```

### 3. 杰卡德相似度（Jaccard Similarity）

杰卡德相似度用于衡量两个集合的相似性。

```java
public class JaccardSimilarityCalculator {
    
    public static double calculate(Set<String> set1, Set<String> set2) {
        if (set1.isEmpty() && set2.isEmpty()) {
            return 1.0; // 两个空集被认为是完全相似的
        }
        
        // 计算交集
        Set<String> intersection = new HashSet<>(set1);
        intersection.retainAll(set2);
        
        // 计算并集
        Set<String> union = new HashSet<>(set1);
        union.addAll(set2);
        
        if (union.isEmpty()) {
            return 0.0;
        }
        
        return (double) intersection.size() / union.size();
    }
    
    // 基于词汇的杰卡德相似度
    public static double calculateFromText(String text1, String text2) {
        Set<String> words1 = new HashSet<>(Arrays.asList(preprocessText(text1).split("\\s+")));
        Set<String> words2 = new HashSet<>(Arrays.asList(preprocessText(text2).split("\\s+")));
        
        // 移除空字符串
        words1.remove("");
        words2.remove("");
        
        return calculate(words1, words2);
    }
    
    private static String preprocessText(String text) {
        return text.replaceAll("[^a-zA-Z0-9\\s]", "").toLowerCase().trim();
    }
}
```

## 向量数据库实现

### 简单的内存向量数据库

```java
public class InMemoryVectorDatabase {
    private List<VectorDocument> documents;
    private SimilarityCalculator similarityCalculator;
    private int dimension;
    
    public InMemoryVectorDatabase(int dimension) {
        this.documents = new ArrayList<>();
        this.similarityCalculator = new CosineSimilarityCalculator();
        this.dimension = dimension;
    }
    
    public void addDocument(String id, String content, float[] vector) {
        if (vector.length != dimension) {
            throw new IllegalArgumentException("Vector dimension mismatch");
        }
        documents.add(new VectorDocument(id, content, Arrays.copyOf(vector, dimension)));
    }
    
    public List<VectorSearchResult> search(float[] queryVector, int topK) {
        if (queryVector.length != dimension) {
            throw new IllegalArgumentException("Query vector dimension mismatch");
        }
        
        // 计算所有文档与查询向量的相似度
        List<VectorSearchResult> results = new ArrayList<>();
        for (VectorDocument doc : documents) {
            double similarity = similarityCalculator.calculate(queryVector, doc.getVector());
            results.add(new VectorSearchResult(doc.getId(), similarity));
        }
        
        // 按相似度降序排序
        results.sort((a, b) -> Double.compare(b.getSimilarity(), a.getSimilarity()));
        
        // 返回前topK个结果
        return results.subList(0, Math.min(topK, results.size()));
    }
    
    public VectorDocument getDocument(String id) {
        return documents.stream()
            .filter(doc -> doc.getId().equals(id))
            .findFirst()
            .orElse(null);
    }
    
    public int size() {
        return documents.size();
    }
    
    public void clear() {
        documents.clear();
    }
}

class VectorDocument {
    private String id;
    private String content;
    private float[] vector;
    
    public VectorDocument(String id, String content, float[] vector) {
        this.id = id;
        this.content = content;
        this.vector = vector;
    }
    
    // Getters
    public String getId() { return id; }
    public String getContent() { return content; }
    public float[] getVector() { return vector; }
}

class VectorSearchResult {
    private String documentId;
    private double similarity;
    
    public VectorSearchResult(String documentId, double similarity) {
        this.documentId = documentId;
        this.similarity = similarity;
    }
    
    // Getters
    public String getDocumentId() { return documentId; }
    public double getSimilarity() { return similarity; }
}

interface SimilarityCalculator {
    double calculate(float[] vector1, float[] vector2);
}

class CosineSimilarityCalculator implements SimilarityCalculator {
    @Override
    public double calculate(float[] vector1, float[] vector2) {
        double dotProduct = 0.0;
        double norm1 = 0.0;
        double norm2 = 0.0;
        
        for (int i = 0; i < vector1.length; i++) {
            dotProduct += vector1[i] * vector2[i];
            norm1 += vector1[i] * vector1[i];
            norm2 += vector2[i] * vector2[i];
        }
        
        if (norm1 == 0 || norm2 == 0) {
            return 0.0;
        }
        
        return dotProduct / (Math.sqrt(norm1) * Math.sqrt(norm2));
    }
}
```

## 性能优化技术

### 1. 向量归一化

```java
public class VectorNormalizer {
    
    public static float[] normalize(float[] vector) {
        float[] normalized = new float[vector.length];
        float norm = calculateNorm(vector);
        
        if (norm == 0) {
            return vector; // 零向量直接返回
        }
        
        for (int i = 0; i < vector.length; i++) {
            normalized[i] = vector[i] / norm;
        }
        
        return normalized;
    }
    
    private static float calculateNorm(float[] vector) {
        float sum = 0.0f;
        for (float value : vector) {
            sum += value * value;
        }
        return (float) Math.sqrt(sum);
    }
    
    // 批量归一化
    public static float[][] normalizeBatch(float[][] vectors) {
        float[][] normalized = new float[vectors.length][];
        for (int i = 0; i < vectors.length; i++) {
            normalized[i] = normalize(vectors[i]);
        }
        return normalized;
    }
}
```

### 2. 近似最近邻搜索（Approximate Nearest Neighbor, ANN）

```java
public class ANNVectorDatabase {
    private List<VectorDocument> documents;
    private int numTrees;
    private List<KDTree> trees;
    private Random random;
    
    public ANNVectorDatabase(int dimension, int numTrees) {
        this.documents = new ArrayList<>();
        this.numTrees = numTrees;
        this.trees = new ArrayList<>();
        this.random = new Random(42);
    }
    
    public void buildIndex() {
        // 构建多个KD树以提高搜索准确性
        trees.clear();
        for (int i = 0; i < numTrees; i++) {
            KDTree tree = new KDTree(documents, random.nextInt());
            trees.add(tree);
        }
    }
    
    public List<VectorSearchResult> search(float[] queryVector, int topK) {
        // 使用多个树进行搜索并合并结果
        Map<String, Double> scoreMap = new HashMap<>();
        
        for (KDTree tree : trees) {
            List<VectorSearchResult> treeResults = tree.search(queryVector, topK * 2);
            for (VectorSearchResult result : treeResults) {
                String docId = result.getDocumentId();
                double score = result.getSimilarity();
                scoreMap.merge(docId, score, Double::max); // 取最大相似度
            }
        }
        
        // 按相似度排序并返回前topK个结果
        List<VectorSearchResult> results = scoreMap.entrySet().stream()
            .map(entry -> new VectorSearchResult(entry.getKey(), entry.getValue()))
            .sorted((a, b) -> Double.compare(b.getSimilarity(), a.getSimilarity()))
            .limit(topK)
            .collect(Collectors.toList());
            
        return results;
    }
    
    // KD树实现（简化版）
    static class KDTree {
        private Node root;
        private List<VectorDocument> documents;
        private Random random;
        
        public KDTree(List<VectorDocument> documents, int seed) {
            this.documents = documents;
            this.random = new Random(seed);
            this.root = buildTree(documents, 0);
        }
        
        private Node buildTree(List<VectorDocument> docs, int depth) {
            if (docs.isEmpty()) {
                return null;
            }
            
            if (docs.size() == 1) {
                return new Node(docs.get(0), depth);
            }
            
            // 选择分割维度
            int splitDim = depth % docs.get(0).getVector().length;
            
            // 按分割维度排序并选择中位数
            docs.sort(Comparator.comparingDouble(doc -> doc.getVector()[splitDim]));
            int medianIndex = docs.size() / 2;
            
            VectorDocument medianDoc = docs.get(medianIndex);
            List<VectorDocument> leftDocs = docs.subList(0, medianIndex);
            List<VectorDocument> rightDocs = docs.subList(medianIndex + 1, docs.size());
            
            Node node = new Node(medianDoc, depth);
            node.left = buildTree(new ArrayList<>(leftDocs), depth + 1);
            node.right = buildTree(new ArrayList<>(rightDocs), depth + 1);
            
            return node;
        }
        
        public List<VectorSearchResult> search(float[] queryVector, int topK) {
            PriorityQueue<SearchCandidate> candidates = new PriorityQueue<>(
                Comparator.comparingDouble(SearchCandidate::getDistance));
            
            searchRecursive(root, queryVector, candidates, topK);
            
            // 转换为结果列表
            List<VectorSearchResult> results = new ArrayList<>();
            while (!candidates.isEmpty()) {
                SearchCandidate candidate = candidates.poll();
                results.add(new VectorSearchResult(
                    candidate.getDocument().getId(), 
                    1.0 / (1.0 + candidate.getDistance()))); // 转换为相似度
            }
            
            return results;
        }
        
        private void searchRecursive(Node node, float[] queryVector, 
                                   PriorityQueue<SearchCandidate> candidates, int topK) {
            if (node == null) {
                return;
            }
            
            // 计算到当前节点的距离
            double distance = euclideanDistance(queryVector, node.document.getVector());
            candidates.offer(new SearchCandidate(node.document, distance));
            
            // 保持候选集大小不超过topK
            if (candidates.size() > topK) {
                candidates.poll();
            }
            
            // 递归搜索子树
            int splitDim = node.depth % queryVector.length;
            Node nextNode = queryVector[splitDim] < node.document.getVector()[splitDim] ? 
                           node.left : node.right;
            Node otherNode = nextNode == node.left ? node.right : node.left;
            
            searchRecursive(nextNode, queryVector, candidates, topK);
            
            // 如果可能包含更近的点，则搜索另一子树
            if (candidates.size() < topK || 
                Math.abs(queryVector[splitDim] - node.document.getVector()[splitDim]) < 
                candidates.peek().getDistance()) {
                searchRecursive(otherNode, queryVector, candidates, topK);
            }
        }
        
        private double euclideanDistance(float[] v1, float[] v2) {
            double sum = 0.0;
            for (int i = 0; i < v1.length; i++) {
                double diff = v1[i] - v2[i];
                sum += diff * diff;
            }
            return Math.sqrt(sum);
        }
        
        static class Node {
            VectorDocument document;
            int depth;
            Node left;
            Node right;
            
            Node(VectorDocument document, int depth) {
                this.document = document;
                this.depth = depth;
            }
        }
        
        static class SearchCandidate {
            VectorDocument document;
            double distance;
            
            SearchCandidate(VectorDocument document, double distance) {
                this.document = document;
                this.distance = distance;
            }
            
            VectorDocument getDocument() { return document; }
            double getDistance() { return distance; }
        }
    }
}
```

## 实际应用示例

### 文档检索系统

```java
public class DocumentRetrievalSystem {
    private SentenceEmbeddingVectorizer vectorizer;
    private InMemoryVectorDatabase vectorDB;
    private DocumentProcessor documentProcessor;
    
    public DocumentRetrievalSystem(EmbeddingModel embeddingModel) {
        this.vectorizer = new SentenceEmbeddingVectorizer(embeddingModel);
        this.vectorDB = new InMemoryVectorDatabase(embeddingModel.getEmbeddingDimension());
        this.documentProcessor = new DocumentProcessor();
    }
    
    public void indexDocument(String id, String content) {
        // 1. 文档预处理
        String processedContent = documentProcessor.process(content);
        
        // 2. 向量化
        float[] vector = vectorizer.vectorize(processedContent);
        
        // 3. 存储到向量数据库
        vectorDB.addDocument(id, processedContent, vector);
    }
    
    public List<RetrievedDocument> search(String query, int topK) {
        // 1. 查询预处理
        String processedQuery = documentProcessor.process(query);
        
        // 2. 查询向量化
        float[] queryVector = vectorizer.vectorize(processedQuery);
        
        // 3. 向量检索
        List<VectorSearchResult> searchResults = vectorDB.search(queryVector, topK);
        
        // 4. 构建检索结果
        List<RetrievedDocument> results = new ArrayList<>();
        for (VectorSearchResult result : searchResults) {
            VectorDocument doc = vectorDB.getDocument(result.getDocumentId());
            results.add(new RetrievedDocument(doc.getContent(), result.getSimilarity()));
        }
        
        return results;
    }
    
    public void batchIndexDocuments(List<Document> documents) {
        for (Document doc : documents) {
            indexDocument(doc.getId(), doc.getContent());
        }
    }
}

class DocumentProcessor {
    public String process(String content) {
        // 移除多余空格和标点符号
        String processed = content.replaceAll("\\s+", " ").trim();
        processed = processed.replaceAll("[^a-zA-Z0-9\\s.,!?;:]", "");
        return processed;
    }
}

class RetrievedDocument {
    private String content;
    private double similarity;
    
    public RetrievedDocument(String content, double similarity) {
        this.content = content;
        this.similarity = similarity;
    }
    
    // Getters
    public String getContent() { return content; }
    public double getSimilarity() { return similarity; }
}

class Document {
    private String id;
    private String content;
    
    public Document(String id, String content) {
        this.id = id;
        this.content = content;
    }
    
    // Getters
    public String getId() { return id; }
    public String getContent() { return content; }
}
```

## 本节小结

本节我们深入探讨了文档向量化与相似度计算的核心技术，包括：

1. **文档向量化方法**：
   - 词袋模型（BoW）：最基础的向量化方法
   - TF-IDF：考虑词频和逆文档频率的统计方法
   - 词嵌入：捕捉词汇语义关系的分布式表示
   - 句子嵌入：更好地表示整个句子语义的技术

2. **相似度计算方法**：
   - 余弦相似度：衡量向量夹角的余弦值
   - 欧氏距离：衡量向量之间的直线距离
   - 杰卡德相似度：衡量集合之间的相似性

3. **向量数据库实现**：
   - 内存向量数据库的基本实现
   - 近似最近邻搜索（ANN）技术

4. **性能优化技术**：
   - 向量归一化
   - KD树等索引结构

5. **实际应用示例**：
   - 完整的文档检索系统实现

通过本节的学习，我们掌握了RAG系统中检索器模块的核心技术，为构建高效的文档检索系统奠定了坚实基础。在下一节中，我们将学习知识图谱构建与维护技术，进一步提升系统的知识管理能力。