# TinyAI Agent Context 技术架构文档

## 1. 项目概述

TinyAI Agent Context 是一个基于 Java 实现的高级智能体（Agent）基础框架，提供了完整的记忆管理、检索增强生成（RAG）、工具调用和上下文工程等核心功能。该模块为构建智能对话系统和 LLM 应用提供了坚实的基础架构。

### 1.1 核心特性

- **多层记忆系统**：支持工作记忆、情节记忆和语义记忆的分层管理
- **检索增强生成**：集成 RAG 系统，支持知识库构建和智能检索
- **工具调用框架**：可扩展的工具注册和调用机制
- **上下文工程**：智能的上下文构建和管理引擎
- **持久化存储**：基于 SQLite 的记忆数据持久化
- **模块化设计**：高内聚、低耦合的组件化架构

### 1.2 技术栈

- **开发语言**：Java 8+
- **数据库**：SQLite（内存或文件模式）
- **构建工具**：Maven
- **测试框架**：JUnit

## 2. 整体架构设计

### 2.1 架构概览

```
┌─────────────────────────────────────────────────────────┐
│                  AdvancedAgent                          │
│                  (智能体核心)                            │
├─────────────────────────────────────────────────────────┤
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐     │
│  │MemoryManager│  │  RAGSystem  │  │ToolRegistry │     │
│  │  (记忆管理)  │  │ (检索系统)  │  │ (工具注册)  │     │
│  └─────────────┘  └─────────────┘  └─────────────┘     │
│                                                         │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐     │
│  │ContextEngine│  │LLMSimulator │  │ AgentHelper │     │
│  │ (上下文引擎) │  │ (LLM模拟器) │  │ (辅助工具)  │     │
│  └─────────────┘  └─────────────┘  └─────────────┘     │
├─────────────────────────────────────────────────────────┤
│                    数据模型层                            │
│  Memory │ Message │ Document │ ToolCall │ RetrievalResult│
└─────────────────────────────────────────────────────────┘
```

### 2.2 分层架构

1. **应用层**：`AdvancedAgent` - 统一的智能体入口
2. **服务层**：各个功能组件（记忆、RAG、工具等）
3. **数据层**：数据模型和持久化存储
4. **工具层**：辅助工具和实用函数

### 2.3 设计模式应用

- **组合模式**：`AdvancedAgent` 组合多个功能组件
- **策略模式**：不同类型的记忆处理策略
- **工厂模式**：工具创建和注册机制
- **观察者模式**：记忆访问统计和整合机制

## 3. 核心组件详解

### 3.1 AdvancedAgent（智能体核心）

#### 3.1.1 职责描述

`AdvancedAgent` 是整个系统的核心协调者，负责：

- 统一的消息处理入口
- 各个子系统的协调调用
- 对话状态和会话管理
- 系统配置和初始化

#### 3.1.2 核心方法

```java
public class AdvancedAgent {
    // 主要处理方法
    public String processMessage(String userInput);
    
    // 知识管理
    public void addKnowledge(String content, String docId, Map<String, Object> metadata);
    
    // 工具注册
    public void registerTool(String name, Function<Map<String, Object>, Object> function, String description);
    
    // 统计信息
    public Map<String, Object> getStats();
}
```

#### 3.1.3 消息处理流程

1. **输入记录**：记录用户消息到对话历史
2. **记忆存储**：将输入存储到情节记忆
3. **记忆检索**：检索相关的历史记忆
4. **知识检索**：从 RAG 系统检索相关文档
5. **上下文构建**：整合各种信息构建完整上下文
6. **响应生成**：调用 LLM 生成响应
7. **工具执行**：解析并执行工具调用
8. **状态更新**：更新对话状态和记忆

### 3.2 MemoryManager（记忆管理系统）

#### 3.2.1 记忆类型

- **工作记忆（Working Memory）**
  - 容量限制：默认 10 条
  - 生命周期：短期，会被自动清理
  - 用途：存储当前对话上下文中的临时信息

- **情节记忆（Episodic Memory）**
  - 容量：无限制
  - 生命周期：长期保存
  - 用途：存储对话事件和用户交互历史

- **语义记忆（Semantic Memory）**
  - 容量：无限制
  - 组织方式：按关键词索引
  - 用途：存储知识和概念信息

#### 3.2.2 记忆整合机制

```java
public void consolidateMemories() {
    // 根据访问频率和重要性将工作记忆转移到长期记忆
    for (Memory memory : workingMemory) {
        if (memory.getAccessCount() > 2 || memory.getImportance() > 0.7) {
            // 转移到情节记忆
            memory.setMemoryType("episodic");
            episodicMemory.add(memory);
        }
    }
}
```

#### 3.2.3 记忆检索算法

- **关键词匹配**：基于词汇重叠度计算相关性
- **重要性排序**：综合考虑重要性分数和访问频率
- **访问统计**：记录访问次数和最后访问时间

### 3.3 RAGSystem（检索增强生成系统）

#### 3.3.1 系统架构

```
文档库 (Documents) → 文本嵌入 (SimpleEmbedding) → 相似度计算 → 检索结果
    ↓                        ↓                        ↓           ↓
  文档索引              嵌入向量缓存              相似度排序    上下文生成
```

#### 3.3.2 文本嵌入实现

基于 TF-IDF 的简化嵌入算法：

```java
public class SimpleEmbedding {
    private Map<String, Integer> vocab;      // 词汇表
    private Map<String, Double> idf;         // 逆文档频率
    
    public List<Double> encode(String text) {
        // 计算TF-IDF向量并归一化
    }
    
    public double similarity(List<Double> vec1, List<Double> vec2) {
        // 计算余弦相似度
    }
}
```

#### 3.3.3 检索流程

1. **查询编码**：将查询文本转换为嵌入向量
2. **相似度计算**：计算查询向量与所有文档向量的相似度
3. **结果排序**：按相似度从高到低排序
4. **上下文生成**：根据长度限制生成最终上下文

### 3.4 ToolRegistry（工具注册表）

#### 3.4.1 工具管理机制

```java
public class ToolRegistry {
    private Map<String, Tool> tools;  // 工具映射表
    
    // 工具注册
    public void register(String name, Function<Map<String, Object>, Object> function, 
                        String description, Map<String, Object> parameters);
    
    // 工具调用
    public ToolCall callTool(String name, Map<String, Object> arguments);
}
```

#### 3.4.2 内置工具

- **计算器工具**：支持四则运算
- **时间工具**：获取当前时间信息
- **笔记工具**：笔记的创建、查看、列出、删除

#### 3.4.3 工具调用流程

1. **解析调用**：从文本中解析工具调用请求
2. **参数验证**：验证调用参数的合法性
3. **工具执行**：调用对应的工具函数
4. **结果处理**：处理执行结果或错误信息
5. **记忆记录**：将工具调用记录到记忆系统

### 3.5 ContextEngine（上下文工程引擎）

#### 3.5.1 上下文构建策略

上下文按优先级组织：

1. **系统指令**：最高优先级，始终保留
2. **工具信息**：可用工具的描述信息
3. **相关记忆**：从记忆系统检索的相关信息
4. **RAG 上下文**：从知识库检索的相关文档
5. **对话历史**：压缩的近期对话记录
6. **当前查询**：用户的当前问题

#### 3.5.2 长度控制机制

```java
private String truncateContext(String context) {
    if (context.length() <= maxContextLength) {
        return context;
    }
    
    // 优先保留系统指令和当前查询
    // 动态截断中间部分内容
    // 确保重要信息不丢失
}
```

#### 3.5.3 对话历史压缩

- **数量限制**：最多保留最近 6 条消息（3 轮对话）
- **长度截断**：单条消息超过 200 字符时进行截断
- **角色映射**：将英文角色名转换为中文显示

## 4. 数据模型设计

### 4.1 核心数据结构

#### 4.1.1 Memory（记忆单元）

```java
public class Memory {
    private String id;                    // 记忆唯一标识
    private String content;               // 记忆内容
    private String memoryType;            // 记忆类型
    private LocalDateTime timestamp;      // 创建时间
    private double importance;            // 重要性分数
    private int accessCount;              // 访问次数
    private LocalDateTime lastAccessed;   // 最后访问时间
    private Map<String, Object> metadata; // 元数据
}
```

#### 4.1.2 Document（文档）

```java
public class Document {
    private String id;                    // 文档ID
    private String content;               // 文档内容
    private LocalDateTime timestamp;      // 创建/更新时间
    private Map<String, Object> metadata; // 文档元数据
}
```

#### 4.1.3 ToolCall（工具调用）

```java
public class ToolCall {
    private String id;                    // 调用ID
    private String name;                  // 工具名称
    private Map<String, Object> arguments; // 调用参数
    private Object result;                // 执行结果
    private String error;                 // 错误信息
    private LocalDateTime timestamp;      // 调用时间
}
```

### 4.2 数据持久化

#### 4.2.1 SQLite 数据库设计

```sql
CREATE TABLE memories (
    id TEXT PRIMARY KEY,
    content TEXT NOT NULL,
    memory_type TEXT NOT NULL,
    timestamp REAL NOT NULL,
    importance REAL DEFAULT 0.0,
    access_count INTEGER DEFAULT 0,
    last_accessed REAL,
    embedding TEXT,
    metadata TEXT
);
```

#### 4.2.2 数据访问模式

- **连接管理**：使用连接池管理数据库连接
- **事务控制**：确保数据一致性
- **错误处理**：完善的异常处理机制

## 5. 关键算法实现

### 5.1 记忆检索算法

#### 5.1.1 相关性计算

```java
private boolean isRelevant(String query, String content) {
    Set<String> queryWords = extractWords(query.toLowerCase());
    Set<String> contentWords = extractWords(content.toLowerCase());
    
    // 计算词汇重叠度
    Set<String> intersection = new HashSet<>(queryWords);
    intersection.retainAll(contentWords);
    
    return !intersection.isEmpty();
}
```

#### 5.1.2 重要性排序

- 主要排序：重要性分数（降序）
- 次要排序：访问次数（降序）
- 时间衰减：考虑时间因素的权重调整

### 5.2 文本嵌入算法

#### 5.2.1 TF-IDF 实现

```java
public List<Double> encode(String text) {
    // 1. 词频统计
    Map<String, Integer> wordCounts = getWordCounts(text);
    
    // 2. TF-IDF 计算
    List<Double> vector = new ArrayList<>();
    for (String word : vocab.keySet()) {
        double tf = wordCounts.getOrDefault(word, 0) / (double) words.size();
        double idf = this.idf.getOrDefault(word, 1.0);
        vector.add(tf * idf);
    }
    
    // 3. 向量归一化
    return normalize(vector);
}
```

#### 5.2.2 相似度计算

使用余弦相似度：

```java
public double similarity(List<Double> vec1, List<Double> vec2) {
    double dotProduct = 0.0;
    double norm1 = 0.0;
    double norm2 = 0.0;
    
    for (int i = 0; i < vec1.size(); i++) {
        dotProduct += vec1.get(i) * vec2.get(i);
        norm1 += vec1.get(i) * vec1.get(i);
        norm2 += vec2.get(i) * vec2.get(i);
    }
    
    return dotProduct / (Math.sqrt(norm1) * Math.sqrt(norm2));
}
```

## 6. 性能优化策略

### 6.1 内存管理

- **容量限制**：工作记忆容量限制防止内存溢出
- **延迟加载**：按需加载记忆数据
- **缓存策略**：常用记忆的内存缓存

### 6.2 检索优化

- **索引建立**：为记忆和文档建立高效索引
- **分页查询**：大量数据的分页处理
- **相似度预计算**：缓存常用查询的相似度结果

### 6.3 上下文优化

- **智能截断**：保留最重要的上下文信息
- **压缩算法**：对话历史的智能压缩
- **长度控制**：严格的长度限制机制

## 7. 扩展性设计

### 7.1 插件化架构

- **工具插件**：支持动态注册新工具
- **记忆插件**：支持不同的记忆存储后端
- **嵌入插件**：支持不同的文本嵌入算法

### 7.2 配置化设计

```java
public class AgentConfig {
    private int maxContextLength = 4000;        // 最大上下文长度
    private int workingMemorySize = 10;         // 工作记忆容量
    private int embeddingDimension = 128;       // 嵌入向量维度
    private String databasePath = ":memory:";   // 数据库路径
}
```

### 7.3 接口抽象

- **MemoryProvider 接口**：支持不同的记忆存储实现
- **EmbeddingModel 接口**：支持不同的嵌入模型
- **LLMProvider 接口**：支持不同的 LLM 实现

## 8. 安全性考虑

### 8.1 输入验证

- **参数检查**：严格的输入参数验证
- **SQL 注入防护**：使用预编译语句
- **内容过滤**：敏感内容的过滤机制

### 8.2 资源限制

- **内存限制**：防止内存使用过量
- **执行时间限制**：工具调用的超时机制
- **存储限制**：数据库大小的监控和清理

### 8.3 错误处理

- **异常捕获**：完善的异常处理机制
- **降级策略**：关键组件故障时的降级处理
- **日志记录**：详细的操作日志记录

## 9. 测试策略

### 9.1 单元测试

- **组件测试**：每个核心组件的独立测试
- **算法测试**：关键算法的准确性测试
- **边界测试**：边界条件和异常情况测试

### 9.2 集成测试

- **组件协作**：多个组件协作的集成测试
- **端到端测试**：完整流程的端到端测试
- **性能测试**：系统性能和负载测试

### 9.3 测试覆盖率

- **代码覆盖率**：确保关键代码路径的覆盖
- **功能覆盖率**：确保所有功能特性的测试
- **场景覆盖率**：确保典型使用场景的覆盖

## 10. 部署和运维

### 10.1 部署要求

- **Java 版本**：JDK 8 或更高版本
- **内存要求**：建议最少 512MB 堆内存
- **磁盘空间**：根据数据量确定存储需求

### 10.2 配置管理

- **环境配置**：支持不同环境的配置文件
- **参数调优**：关键参数的性能调优指南
- **监控指标**：系统运行状态的关键指标

### 10.3 故障排查

- **日志分析**：详细的日志记录和分析
- **性能监控**：内存、CPU、响应时间监控
- **问题诊断**：常见问题的诊断和解决方案

## 11. 未来规划

### 11.1 功能增强

- **多模态支持**：支持图像、音频等多模态输入
- **分布式架构**：支持分布式部署和扩展
- **实时学习**：在线学习和模型更新能力

### 11.2 性能优化

- **算法优化**：更高效的检索和相似度算법
- **并发优化**：支持高并发的系统架构
- **缓存优化**：更智能的缓存策略

### 11.3 生态集成

- **Spring 集成**：与 Spring Boot 框架的集成
- **云原生支持**：支持容器化和云原生部署
- **API 标准化**：遵循行业标准的 API 设计

## 12. 总结

TinyAI Agent Base 提供了一个完整、可扩展的智能体基础框架，通过模块化的设计和丰富的功能组件，为构建高级 LLM 应用提供了坚实的基础。该架构具有以下优势：

1. **完整性**：涵盖了智能体系统的核心功能需求
2. **可扩展性**：灵活的插件化和配置化设计
3. **可维护性**：清晰的架构分层和组件解耦
4. **高性能**：优化的算法和数据结构设计
5. **易用性**：简洁的 API 和完善的文档

通过持续的迭代和优化，该框架将为 Java 生态系统中的 AI 应用开发提供更加强大和便捷的基础设施支持。

---

*文档版本：1.0*  
*最后更新：2025年10月*  
*作者：山泽*